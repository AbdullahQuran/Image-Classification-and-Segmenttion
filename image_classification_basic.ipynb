{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Homework1_Basic",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xMuh-F_CQxc",
        "colab_type": "text"
      },
      "source": [
        "Solution 1: building model from scratch wothout transfer learning - Val_accuracy: 67.1% - test accuracy: \n",
        "\n",
        "parameters:\n",
        "7 conv layaers \n",
        "5 Dense layers - relu activation  \n",
        "1 softmax \n",
        "\n",
        "optimizer: ADAM with lr = 0.0001\n",
        "dropout: 40% \n",
        "Augmentation: yes\n",
        "class weights added to compensate for data imbalance\n",
        "\n",
        "note: i have a problem with result reproducibility, I have fixed a seed for tensorflow, keras and used keras intitilaiztion in the dense layers. but the results differ a little bit for run to another. I think this randomness comes from cloud GPU. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFAABqTseS3k",
        "colab_type": "text"
      },
      "source": [
        "Impoting data from googe drive and importing the useful libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEms5sLrvWWM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f29f20c1-d61c-4bce-c0e3-1276d6ab0cfb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8Paft5bvdFj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir = \"/content/drive/My Drive/classification/classification/Classification_Dataset/training\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZYXERSVvghm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "ff5c1ffd-2ac6-46de-fbef-e3e0922abee0"
      },
      "source": [
        "#try:\n",
        "  # Use the %tensorflow_version magic if in colab.\n",
        "  #%tensorflow_version 2.x\n",
        "#except Exception:\n",
        "  #pass\n",
        "\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YT-ht_dmvtrE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "93569178-3091-4213-e0cd-36a40d8aaf7b"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import shutil\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense,GlobalAveragePooling2D,Dropout,SeparableConv2D, BatchNormalization, Activation,  Conv2D, Flatten, MaxPooling2D\n",
        "from keras.applications.mobilenet import MobileNet\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.datasets import load_files  # to load the images from the subfolders    \n",
        "from keras.utils import np_utils # to hot encode the label of the image\n",
        "import matplotlib.pyplot as plt # to draw barplot and etc...\n",
        "from tqdm import tqdm \n",
        "from keras.preprocessing import image    \n",
        "from keras.callbacks import ModelCheckpoint # to save the best weights for the model while training \n",
        "import random as rn\n",
        "from sklearn.utils import class_weight\n",
        "from datetime import datetime\n",
        "import cv2\n",
        "from PIL import Image\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhD9IS5ZejtL",
        "colab_type": "text"
      },
      "source": [
        "Fixing a random seed to make the results reproducible"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpE-PL7Dvxj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rand_seed = 19\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "\n",
        "#random seed for NP genreator of ranodm numbers\n",
        "np.random.seed(rand_seed)\n",
        "\n",
        "#random seed generator for Python\n",
        "rn.seed(rand_seed)\n",
        "\n",
        "#random seed for tensorflow\n",
        "tf.set_random_seed(rand_seed)\n",
        "\n",
        "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnUL4cFseqo9",
        "colab_type": "text"
      },
      "source": [
        "defining the classes in the correct order {owl: 0, galaxy: 2, ... "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FiYVs1MEmNHf",
        "colab": {}
      },
      "source": [
        "class_list = [\n",
        "              'owl',\n",
        "              'galaxy',\n",
        "              'lightning',\n",
        "              'wine-bottle',\n",
        "              't-shirt',\n",
        "              'waterfall',\n",
        "              'sword',\n",
        "              'school-bus',\n",
        "              'calculator',\n",
        "              'sheet-music',\n",
        "              'airplanes',\n",
        "              'lightbulb',\n",
        "              'skyscraper',\n",
        "              'mountain-bike',\n",
        "              'fireworks',\n",
        "              'computer-monitor',\n",
        "              'bear',\n",
        "              'grand-piano',\n",
        "              'kangaroo',\n",
        "              'laptop'\n",
        "              ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vS_YYrae2Q0",
        "colab_type": "text"
      },
      "source": [
        " since the data is not splitted into training and vailation sets. i will do so in the next code .The code below creates a train and a val folder each containing 20 folders (one for each type of class). It then moves the images from the original folders to these new folders such that 80% of the images go to the training set and 20% of the images go into the validation set. In the end our directory will have the \n",
        "\n",
        "Since I did nott delete the original folders, they will still be in the directory which is ok "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPbtePVzJ-R7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "outputId": "1be25a95-b9dd-4d85-dc87-64a1359070ea"
      },
      "source": [
        "train_list = []\n",
        "val_list = []\n",
        "train_dict = {}\n",
        "val_dict = {}\n",
        "\n",
        "for cl in class_list:\n",
        "  img_path = os.path.join(base_dir, cl)\n",
        "  #print(img_path)\n",
        "  images = glob.glob(img_path + '/*')\n",
        "  #print(\"{}: {} Images\".format(cl, len(images)))\n",
        "  num_train = int(round(len(images)*0.8))\n",
        "  train, val = images[:num_train], images[num_train:]\n",
        "\n",
        "  for t in train:\n",
        "    if not os.path.exists(os.path.join(base_dir, 'train', cl)):\n",
        "      os.makedirs(os.path.join(base_dir, 'train', cl))\n",
        "    shutil.move(t, os.path.join(base_dir, 'train', cl))\n",
        "\n",
        "  for v in val:\n",
        "    if not os.path.exists(os.path.join(base_dir, 'val', cl)):\n",
        "      os.makedirs(os.path.join(base_dir, 'val', cl))\n",
        "    shutil.move(v, os.path.join(base_dir, 'val', cl))\n",
        "\n",
        "    \n",
        "########################################### JOSN Data split file generation ##############################\n",
        "  for image in glob.glob(os.path.join(base_dir, 'train', cl) + '/*.jpg'):\n",
        "      train_list.append(image)\n",
        "      train_dict.setdefault (cl , []).append(os.path.basename(image)) \n",
        "      #print(image)\n",
        "      \n",
        "  for image in glob.glob(os.path.join(base_dir, 'val', cl) + '/*.jpg'):\n",
        "      val_list.append(image)\n",
        "      val_dict.setdefault (cl , []).append(os.path.basename(image))   \n",
        "   \n",
        "dataset_split = {'training' : train_dict , 'validation' : val_dict }\n",
        "\n",
        "print(dataset_split)\n",
        "import json\n",
        "with open('dataset_split.json', 'w') as fp:\n",
        "      json.dump(dataset_split, fp)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'training': {'owl': ['IMG_1018.jpg', 'IMG_1022.jpg', 'IMG_1026.jpg', 'IMG_1039.jpg', 'IMG_1044.jpg', 'IMG_1065.jpg', 'IMG_1087.jpg', 'IMG_1088.jpg', 'IMG_1091.jpg', 'IMG_1092.jpg', 'IMG_1112.jpg', 'IMG_1113.jpg', 'IMG_1120.jpg', 'IMG_1145.jpg', 'IMG_1150.jpg', 'IMG_1162.jpg', 'IMG_1170.jpg', 'IMG_1175.jpg', 'IMG_1182.jpg', 'IMG_1223.jpg', 'IMG_1236.jpg', 'IMG_1275.jpg', 'IMG_1286.jpg', 'IMG_1301.jpg', 'IMG_1319.jpg', 'IMG_1326.jpg', 'IMG_1362.jpg', 'IMG_1366.jpg', 'IMG_1373.jpg', 'IMG_1375.jpg', 'IMG_1380.jpg', 'IMG_1388.jpg', 'IMG_1403.jpg', 'IMG_1423.jpg', 'IMG_1425.jpg', 'IMG_1432.jpg', 'IMG_146.jpg', 'IMG_1482.jpg', 'IMG_1598.jpg', 'IMG_1673.jpg', 'IMG_1677.jpg', 'IMG_1694.jpg', 'IMG_1711.jpg', 'IMG_1714.jpg', 'IMG_1715.jpg', 'IMG_1753.jpg', 'IMG_1766.jpg', 'IMG_1779.jpg', 'IMG_1795.jpg', 'IMG_1841.jpg', 'IMG_1920.jpg', 'IMG_1922.jpg', 'IMG_1927.jpg', 'IMG_1954.jpg', 'IMG_1980.jpg', 'IMG_1983.jpg', 'IMG_1993.jpg', 'IMG_1997.jpg', 'IMG_2011.jpg', 'IMG_2048.jpg', 'IMG_258.jpg', 'IMG_26.jpg', 'IMG_274.jpg', 'IMG_290.jpg', 'IMG_319.jpg', 'IMG_330.jpg', 'IMG_332.jpg', 'IMG_357.jpg', 'IMG_399.jpg', 'IMG_431.jpg', 'IMG_434.jpg', 'IMG_462.jpg', 'IMG_484.jpg', 'IMG_50.jpg', 'IMG_530.jpg', 'IMG_541.jpg'], 'galaxy': ['IMG_1118.jpg', 'IMG_1144.jpg', 'IMG_1151.jpg', 'IMG_1188.jpg', 'IMG_1198.jpg', 'IMG_1227.jpg', 'IMG_1253.jpg', 'IMG_1284.jpg', 'IMG_1296.jpg', 'IMG_1303.jpg', 'IMG_1492.jpg', 'IMG_1496.jpg', 'IMG_1530.jpg', 'IMG_1592.jpg', 'IMG_1619.jpg', 'IMG_162.jpg', 'IMG_164.jpg', 'IMG_1656.jpg', 'IMG_170.jpg', 'IMG_1702.jpg', 'IMG_1796.jpg', 'IMG_1856.jpg', 'IMG_1866.jpg', 'IMG_194.jpg', 'IMG_1958.jpg', 'IMG_1968.jpg', 'IMG_1984.jpg', 'IMG_1985.jpg', 'IMG_20.jpg', 'IMG_2004.jpg', 'IMG_2008.jpg', 'IMG_211.jpg', 'IMG_212.jpg', 'IMG_219.jpg', 'IMG_254.jpg', 'IMG_281.jpg', 'IMG_292.jpg', 'IMG_315.jpg', 'IMG_336.jpg', 'IMG_417.jpg', 'IMG_432.jpg', 'IMG_45.jpg', 'IMG_518.jpg', 'IMG_531.jpg', 'IMG_593.jpg'], 'lightning': ['IMG_1006.jpg', 'IMG_1012.jpg', 'IMG_1020.jpg', 'IMG_1034.jpg', 'IMG_1066.jpg', 'IMG_1068.jpg', 'IMG_1077.jpg', 'IMG_1081.jpg', 'IMG_11.jpg', 'IMG_1125.jpg', 'IMG_1130.jpg', 'IMG_1146.jpg', 'IMG_1159.jpg', 'IMG_118.jpg', 'IMG_1181.jpg', 'IMG_1192.jpg', 'IMG_1234.jpg', 'IMG_1246.jpg', 'IMG_1262.jpg', 'IMG_1265.jpg', 'IMG_1273.jpg', 'IMG_1277.jpg', 'IMG_1279.jpg', 'IMG_1281.jpg', 'IMG_1287.jpg', 'IMG_1358.jpg', 'IMG_1372.jpg', 'IMG_1413.jpg', 'IMG_143.jpg', 'IMG_1434.jpg', 'IMG_1439.jpg', 'IMG_1451.jpg', 'IMG_1453.jpg', 'IMG_1472.jpg', 'IMG_148.jpg', 'IMG_1498.jpg', 'IMG_1523.jpg', 'IMG_1565.jpg', 'IMG_1576.jpg', 'IMG_1578.jpg', 'IMG_161.jpg', 'IMG_1629.jpg', 'IMG_1635.jpg', 'IMG_1678.jpg', 'IMG_1680.jpg', 'IMG_1690.jpg', 'IMG_1720.jpg', 'IMG_1746.jpg', 'IMG_1810.jpg', 'IMG_1818.jpg', 'IMG_1825.jpg', 'IMG_1839.jpg', 'IMG_1846.jpg', 'IMG_1855.jpg', 'IMG_1926.jpg', 'IMG_1932.jpg', 'IMG_1940.jpg', 'IMG_1959.jpg', 'IMG_1972.jpg', 'IMG_1994.jpg', 'IMG_2003.jpg', 'IMG_2019.jpg', 'IMG_2030.jpg', 'IMG_205.jpg', 'IMG_209.jpg', 'IMG_213.jpg', 'IMG_23.jpg', 'IMG_230.jpg', 'IMG_243.jpg', 'IMG_284.jpg', 'IMG_331.jpg', 'IMG_339.jpg', 'IMG_345.jpg', 'IMG_358.jpg', 'IMG_366.jpg', 'IMG_390.jpg', 'IMG_401.jpg', 'IMG_419.jpg', 'IMG_454.jpg', 'IMG_468.jpg'], 'wine-bottle': ['IMG_1013.jpg', 'IMG_1062.jpg', 'IMG_1083.jpg', 'IMG_1085.jpg', 'IMG_1109.jpg', 'IMG_1195.jpg', 'IMG_1222.jpg', 'IMG_131.jpg', 'IMG_1313.jpg', 'IMG_1317.jpg', 'IMG_1352.jpg', 'IMG_1364.jpg', 'IMG_1378.jpg', 'IMG_1395.jpg', 'IMG_1398.jpg', 'IMG_14.jpg', 'IMG_1405.jpg', 'IMG_141.jpg', 'IMG_1417.jpg', 'IMG_1426.jpg', 'IMG_1478.jpg', 'IMG_1572.jpg', 'IMG_1580.jpg', 'IMG_1596.jpg', 'IMG_1617.jpg', 'IMG_1624.jpg', 'IMG_1638.jpg', 'IMG_1670.jpg', 'IMG_168.jpg', 'IMG_1689.jpg', 'IMG_17.jpg', 'IMG_1710.jpg', 'IMG_1725.jpg', 'IMG_1755.jpg', 'IMG_1792.jpg', 'IMG_1793.jpg', 'IMG_1812.jpg', 'IMG_443.jpg', 'IMG_458.jpg', 'IMG_463.jpg', 'IMG_470.jpg', 'IMG_502.jpg', 'IMG_506.jpg', 'IMG_525.jpg', 'IMG_529.jpg', 'IMG_536.jpg', 'IMG_56.jpg', 'IMG_560.jpg', 'IMG_566.jpg', 'IMG_585.jpg', 'IMG_637.jpg', 'IMG_653.jpg', 'IMG_666.jpg', 'IMG_738.jpg', 'IMG_741.jpg', 'IMG_758.jpg', 'IMG_773.jpg', 'IMG_8.jpg', 'IMG_806.jpg', 'IMG_811.jpg', 'IMG_82.jpg'], 't-shirt': ['IMG_1009.jpg', 'IMG_1010.jpg', 'IMG_1043.jpg', 'IMG_1047.jpg', 'IMG_1063.jpg', 'IMG_1078.jpg', 'IMG_109.jpg', 'IMG_1105.jpg', 'IMG_1108.jpg', 'IMG_1121.jpg', 'IMG_1186.jpg', 'IMG_1191.jpg', 'IMG_1261.jpg', 'IMG_128.jpg', 'IMG_1288.jpg', 'IMG_1295.jpg', 'IMG_1299.jpg', 'IMG_1309.jpg', 'IMG_1314.jpg', 'IMG_1327.jpg', 'IMG_1351.jpg', 'IMG_1355.jpg', 'IMG_1381.jpg', 'IMG_1385.jpg', 'IMG_1386.jpg', 'IMG_1473.jpg', 'IMG_1477.jpg', 'IMG_1486.jpg', 'IMG_1497.jpg', 'IMG_1542.jpg', 'IMG_1568.jpg', 'IMG_1581.jpg', 'IMG_1615.jpg', 'IMG_1639.jpg', 'IMG_1642.jpg', 'IMG_172.jpg', 'IMG_1724.jpg', 'IMG_1760.jpg', 'IMG_178.jpg', 'IMG_1789.jpg', 'IMG_1821.jpg', 'IMG_1824.jpg', 'IMG_1848.jpg', 'IMG_1850.jpg', 'IMG_1884.jpg', 'IMG_191.jpg', 'IMG_1921.jpg', 'IMG_1928.jpg', 'IMG_1952.jpg', 'IMG_1960.jpg', 'IMG_1987.jpg', 'IMG_2027.jpg', 'IMG_203.jpg', 'IMG_2039.jpg', 'IMG_2051.jpg', 'IMG_208.jpg', 'IMG_218.jpg', 'IMG_232.jpg', 'IMG_304.jpg', 'IMG_314.jpg', 'IMG_594.jpg', 'IMG_596.jpg', 'IMG_611.jpg', 'IMG_624.jpg', 'IMG_675.jpg', 'IMG_699.jpg', 'IMG_721.jpg', 'IMG_759.jpg', 'IMG_763.jpg', 'IMG_800.jpg', 'IMG_807.jpg', 'IMG_818.jpg', 'IMG_825.jpg', 'IMG_829.jpg', 'IMG_833.jpg', 'IMG_843.jpg', 'IMG_861.jpg', 'IMG_890.jpg', 'IMG_9.jpg', 'IMG_915.jpg'], 'waterfall': ['IMG_1019.jpg', 'IMG_1028.jpg', 'IMG_103.jpg', 'IMG_1036.jpg', 'IMG_1051.jpg', 'IMG_1069.jpg', 'IMG_1096.jpg', 'IMG_111.jpg', 'IMG_1180.jpg', 'IMG_1220.jpg', 'IMG_1221.jpg', 'IMG_1233.jpg', 'IMG_1410.jpg', 'IMG_1440.jpg', 'IMG_1441.jpg', 'IMG_1447.jpg', 'IMG_1461.jpg', 'IMG_1490.jpg', 'IMG_1499.jpg', 'IMG_1526.jpg', 'IMG_1540.jpg', 'IMG_1660.jpg', 'IMG_1662.jpg', 'IMG_1663.jpg', 'IMG_1700.jpg', 'IMG_1736.jpg', 'IMG_1737.jpg', 'IMG_1740.jpg', 'IMG_1797.jpg', 'IMG_1817.jpg', 'IMG_1828.jpg', 'IMG_1830.jpg', 'IMG_1847.jpg', 'IMG_1874.jpg', 'IMG_1914.jpg', 'IMG_1946.jpg', 'IMG_1967.jpg', 'IMG_1986.jpg', 'IMG_2001.jpg', 'IMG_2044.jpg', 'IMG_22.jpg', 'IMG_226.jpg', 'IMG_256.jpg', 'IMG_277.jpg', 'IMG_324.jpg', 'IMG_381.jpg', 'IMG_392.jpg', 'IMG_409.jpg', 'IMG_413.jpg', 'IMG_424.jpg', 'IMG_465.jpg', 'IMG_47.jpg', 'IMG_477.jpg', 'IMG_540.jpg', 'IMG_615.jpg', 'IMG_636.jpg'], 'sword': ['IMG_1124.jpg', 'IMG_1138.jpg', 'IMG_1139.jpg', 'IMG_1218.jpg', 'IMG_1256.jpg', 'IMG_1274.jpg', 'IMG_1347.jpg', 'IMG_1357.jpg', 'IMG_1414.jpg', 'IMG_1416.jpg', 'IMG_1456.jpg', 'IMG_1513.jpg', 'IMG_1553.jpg', 'IMG_1558.jpg', 'IMG_1573.jpg', 'IMG_1574.jpg', 'IMG_1644.jpg', 'IMG_1679.jpg', 'IMG_1698.jpg', 'IMG_1716.jpg', 'IMG_1772.jpg', 'IMG_1776.jpg', 'IMG_1777.jpg', 'IMG_1778.jpg', 'IMG_1783.jpg', 'IMG_1784.jpg', 'IMG_1816.jpg', 'IMG_185.jpg', 'IMG_186.jpg', 'IMG_187.jpg', 'IMG_1877.jpg', 'IMG_1934.jpg', 'IMG_2009.jpg', 'IMG_235.jpg', 'IMG_236.jpg', 'IMG_246.jpg', 'IMG_260.jpg', 'IMG_286.jpg', 'IMG_287.jpg', 'IMG_305.jpg', 'IMG_316.jpg', 'IMG_320.jpg', 'IMG_351.jpg', 'IMG_394.jpg', 'IMG_395.jpg', 'IMG_398.jpg', 'IMG_42.jpg', 'IMG_435.jpg', 'IMG_439.jpg', 'IMG_479.jpg', 'IMG_519.jpg', 'IMG_522.jpg', 'IMG_527.jpg', 'IMG_683.jpg', 'IMG_704.jpg', 'IMG_719.jpg', 'IMG_728.jpg', 'IMG_743.jpg', 'IMG_819.jpg', 'IMG_883.jpg', 'IMG_886.jpg', 'IMG_933.jpg'], 'school-bus': ['IMG_1014.jpg', 'IMG_1048.jpg', 'IMG_1075.jpg', 'IMG_1111.jpg', 'IMG_1114.jpg', 'IMG_1171.jpg', 'IMG_1185.jpg', 'IMG_1237.jpg', 'IMG_1294.jpg', 'IMG_1361.jpg', 'IMG_1367.jpg', 'IMG_1464.jpg', 'IMG_1471.jpg', 'IMG_1491.jpg', 'IMG_150.jpg', 'IMG_1515.jpg', 'IMG_1519.jpg', 'IMG_1525.jpg', 'IMG_1545.jpg', 'IMG_1570.jpg', 'IMG_1585.jpg', 'IMG_1586.jpg', 'IMG_1676.jpg', 'IMG_1687.jpg', 'IMG_1732.jpg', 'IMG_1742.jpg', 'IMG_1759.jpg', 'IMG_1800.jpg', 'IMG_1805.jpg', 'IMG_1809.jpg', 'IMG_1833.jpg', 'IMG_190.jpg', 'IMG_1904.jpg', 'IMG_192.jpg', 'IMG_1951.jpg', 'IMG_198.jpg', 'IMG_200.jpg', 'IMG_2014.jpg', 'IMG_204.jpg', 'IMG_2045.jpg', 'IMG_216.jpg', 'IMG_242.jpg', 'IMG_268.jpg', 'IMG_326.jpg', 'IMG_36.jpg', 'IMG_373.jpg', 'IMG_396.jpg', 'IMG_40.jpg', 'IMG_428.jpg', 'IMG_449.jpg', 'IMG_453.jpg', 'IMG_510.jpg', 'IMG_565.jpg', 'IMG_586.jpg', 'IMG_587.jpg', 'IMG_609.jpg', 'IMG_619.jpg', 'IMG_673.jpg'], 'calculator': ['IMG_1003.jpg', 'IMG_102.jpg', 'IMG_1025.jpg', 'IMG_1045.jpg', 'IMG_1056.jpg', 'IMG_1110.jpg', 'IMG_1141.jpg', 'IMG_1176.jpg', 'IMG_1250.jpg', 'IMG_1252.jpg', 'IMG_1254.jpg', 'IMG_1267.jpg', 'IMG_1321.jpg', 'IMG_1340.jpg', 'IMG_1348.jpg', 'IMG_1365.jpg', 'IMG_139.jpg', 'IMG_1401.jpg', 'IMG_1428.jpg', 'IMG_1433.jpg', 'IMG_1443.jpg', 'IMG_1510.jpg', 'IMG_155.jpg', 'IMG_1554.jpg', 'IMG_1561.jpg', 'IMG_1563.jpg', 'IMG_1599.jpg', 'IMG_1654.jpg', 'IMG_1667.jpg', 'IMG_1669.jpg', 'IMG_1671.jpg', 'IMG_1686.jpg', 'IMG_1726.jpg', 'IMG_1731.jpg', 'IMG_1749.jpg', 'IMG_1769.jpg', 'IMG_1791.jpg', 'IMG_1801.jpg', 'IMG_1822.jpg', 'IMG_1829.jpg', 'IMG_1863.jpg', 'IMG_1896.jpg', 'IMG_1903.jpg', 'IMG_1942.jpg', 'IMG_1948.jpg', 'IMG_1950.jpg', 'IMG_1995.jpg', 'IMG_1998.jpg', 'IMG_25.jpg', 'IMG_302.jpg', 'IMG_353.jpg', 'IMG_359.jpg', 'IMG_446.jpg', 'IMG_481.jpg', 'IMG_521.jpg', 'IMG_537.jpg', 'IMG_569.jpg', 'IMG_604.jpg', 'IMG_605.jpg', 'IMG_614.jpg'], 'sheet-music': ['IMG_1021.jpg', 'IMG_1067.jpg', 'IMG_1247.jpg', 'IMG_126.jpg', 'IMG_1316.jpg', 'IMG_1368.jpg', 'IMG_1371.jpg', 'IMG_1376.jpg', 'IMG_1393.jpg', 'IMG_1460.jpg', 'IMG_1463.jpg', 'IMG_1479.jpg', 'IMG_1489.jpg', 'IMG_152.jpg', 'IMG_1531.jpg', 'IMG_1559.jpg', 'IMG_1569.jpg', 'IMG_1605.jpg', 'IMG_1627.jpg', 'IMG_1641.jpg', 'IMG_1651.jpg', 'IMG_1665.jpg', 'IMG_1675.jpg', 'IMG_1735.jpg', 'IMG_1843.jpg', 'IMG_1924.jpg', 'IMG_1933.jpg', 'IMG_1937.jpg', 'IMG_1964.jpg', 'IMG_1970.jpg', 'IMG_244.jpg', 'IMG_276.jpg', 'IMG_311.jpg', 'IMG_333.jpg', 'IMG_354.jpg', 'IMG_441.jpg', 'IMG_460.jpg', 'IMG_491.jpg', 'IMG_5.jpg', 'IMG_500.jpg', 'IMG_589.jpg', 'IMG_622.jpg', 'IMG_632.jpg', 'IMG_724.jpg', 'IMG_745.jpg', 'IMG_750.jpg', 'IMG_782.jpg'], 'airplanes': ['IMG_1038.jpg', 'IMG_1054.jpg', 'IMG_1064.jpg', 'IMG_1131.jpg', 'IMG_1160.jpg', 'IMG_1177.jpg', 'IMG_1189.jpg', 'IMG_1201.jpg', 'IMG_1210.jpg', 'IMG_1230.jpg', 'IMG_1259.jpg', 'IMG_1263.jpg', 'IMG_1332.jpg', 'IMG_1335.jpg', 'IMG_1343.jpg', 'IMG_1356.jpg', 'IMG_1387.jpg', 'IMG_1408.jpg', 'IMG_1409.jpg', 'IMG_1418.jpg', 'IMG_1431.jpg', 'IMG_1457.jpg', 'IMG_1458.jpg', 'IMG_1487.jpg', 'IMG_149.jpg', 'IMG_15.jpg', 'IMG_1537.jpg', 'IMG_1587.jpg', 'IMG_1590.jpg', 'IMG_1616.jpg', 'IMG_1621.jpg', 'IMG_1634.jpg', 'IMG_1685.jpg', 'IMG_1697.jpg', 'IMG_1707.jpg', 'IMG_1730.jpg', 'IMG_1773.jpg', 'IMG_1787.jpg', 'IMG_1788.jpg', 'IMG_1790.jpg', 'IMG_1794.jpg', 'IMG_1862.jpg', 'IMG_1891.jpg', 'IMG_1911.jpg', 'IMG_1913.jpg', 'IMG_1930.jpg', 'IMG_1956.jpg', 'IMG_197.jpg', 'IMG_2034.jpg', 'IMG_2040.jpg', 'IMG_210.jpg', 'IMG_229.jpg', 'IMG_259.jpg', 'IMG_301.jpg', 'IMG_334.jpg', 'IMG_337.jpg', 'IMG_342.jpg', 'IMG_361.jpg', 'IMG_391.jpg', 'IMG_41.jpg', 'IMG_415.jpg', 'IMG_429.jpg', 'IMG_437.jpg', 'IMG_444.jpg', 'IMG_445.jpg', 'IMG_472.jpg', 'IMG_476.jpg', 'IMG_49.jpg', 'IMG_490.jpg', 'IMG_493.jpg', 'IMG_511.jpg', 'IMG_538.jpg', 'IMG_553.jpg', 'IMG_554.jpg', 'IMG_556.jpg', 'IMG_577.jpg', 'IMG_579.jpg', 'IMG_625.jpg', 'IMG_629.jpg', 'IMG_650.jpg'], 'lightbulb': ['IMG_1015.jpg', 'IMG_1057.jpg', 'IMG_1103.jpg', 'IMG_1116.jpg', 'IMG_112.jpg', 'IMG_1134.jpg', 'IMG_1136.jpg', 'IMG_1164.jpg', 'IMG_1165.jpg', 'IMG_1168.jpg', 'IMG_1200.jpg', 'IMG_122.jpg', 'IMG_1255.jpg', 'IMG_1260.jpg', 'IMG_1269.jpg', 'IMG_127.jpg', 'IMG_132.jpg', 'IMG_1329.jpg', 'IMG_1333.jpg', 'IMG_1336.jpg', 'IMG_1338.jpg', 'IMG_147.jpg', 'IMG_1476.jpg', 'IMG_1508.jpg', 'IMG_1535.jpg', 'IMG_154.jpg', 'IMG_1612.jpg', 'IMG_1613.jpg', 'IMG_1693.jpg', 'IMG_1708.jpg', 'IMG_1754.jpg', 'IMG_1781.jpg', 'IMG_1782.jpg', 'IMG_1786.jpg', 'IMG_184.jpg', 'IMG_1861.jpg', 'IMG_1864.jpg', 'IMG_1869.jpg', 'IMG_1876.jpg', 'IMG_1981.jpg', 'IMG_199.jpg', 'IMG_1990.jpg', 'IMG_1999.jpg', 'IMG_2002.jpg', 'IMG_2013.jpg', 'IMG_231.jpg', 'IMG_248.jpg', 'IMG_364.jpg', 'IMG_382.jpg', 'IMG_407.jpg', 'IMG_442.jpg', 'IMG_456.jpg', 'IMG_457.jpg', 'IMG_471.jpg'], 'skyscraper': ['IMG_100.jpg', 'IMG_1000.jpg', 'IMG_1029.jpg', 'IMG_1049.jpg', 'IMG_1053.jpg', 'IMG_1102.jpg', 'IMG_1106.jpg', 'IMG_1126.jpg', 'IMG_1135.jpg', 'IMG_114.jpg', 'IMG_1149.jpg', 'IMG_1157.jpg', 'IMG_1169.jpg', 'IMG_1178.jpg', 'IMG_1207.jpg', 'IMG_1215.jpg', 'IMG_1239.jpg', 'IMG_125.jpg', 'IMG_1304.jpg', 'IMG_1310.jpg', 'IMG_1337.jpg', 'IMG_1448.jpg', 'IMG_18.jpg', 'IMG_1844.jpg', 'IMG_1879.jpg', 'IMG_1888.jpg', 'IMG_1897.jpg', 'IMG_1898.jpg', 'IMG_1947.jpg', 'IMG_1976.jpg', 'IMG_1996.jpg', 'IMG_2.jpg', 'IMG_2016.jpg', 'IMG_2022.jpg', 'IMG_3.jpg', 'IMG_313.jpg', 'IMG_347.jpg', 'IMG_378.jpg', 'IMG_44.jpg', 'IMG_448.jpg', 'IMG_466.jpg', 'IMG_514.jpg', 'IMG_599.jpg', 'IMG_617.jpg', 'IMG_684.jpg', 'IMG_693.jpg', 'IMG_697.jpg', 'IMG_715.jpg', 'IMG_718.jpg', 'IMG_73.jpg', 'IMG_774.jpg', 'IMG_809.jpg', 'IMG_859.jpg', 'IMG_875.jpg', 'IMG_931.jpg', 'IMG_989.jpg'], 'mountain-bike': ['IMG_1005.jpg', 'IMG_101.jpg', 'IMG_1086.jpg', 'IMG_1129.jpg', 'IMG_1190.jpg', 'IMG_1245.jpg', 'IMG_1291.jpg', 'IMG_1292.jpg', 'IMG_1300.jpg', 'IMG_1331.jpg', 'IMG_138.jpg', 'IMG_1402.jpg', 'IMG_1438.jpg', 'IMG_1505.jpg', 'IMG_1514.jpg', 'IMG_1518.jpg', 'IMG_1614.jpg', 'IMG_1640.jpg', 'IMG_1733.jpg', 'IMG_1765.jpg', 'IMG_1767.jpg', 'IMG_181.jpg', 'IMG_1868.jpg', 'IMG_1900.jpg', 'IMG_193.jpg', 'IMG_1939.jpg', 'IMG_1943.jpg', 'IMG_1955.jpg', 'IMG_1992.jpg', 'IMG_2026.jpg', 'IMG_2038.jpg', 'IMG_2049.jpg', 'IMG_21.jpg', 'IMG_247.jpg', 'IMG_352.jpg', 'IMG_365.jpg', 'IMG_374.jpg', 'IMG_464.jpg', 'IMG_610.jpg', 'IMG_618.jpg', 'IMG_640.jpg', 'IMG_643.jpg', 'IMG_646.jpg', 'IMG_669.jpg', 'IMG_678.jpg', 'IMG_998.jpg'], 'fireworks': ['IMG_1445.jpg', 'IMG_1032.jpg', 'IMG_1041.jpg', 'IMG_1061.jpg', 'IMG_107.jpg', 'IMG_1095.jpg', 'IMG_1115.jpg', 'IMG_1123.jpg', 'IMG_1203.jpg', 'IMG_1225.jpg', 'IMG_1231.jpg', 'IMG_1244.jpg', 'IMG_1258.jpg', 'IMG_1312.jpg', 'IMG_1320.jpg', 'IMG_1324.jpg', 'IMG_1383.jpg', 'IMG_1399.jpg', 'IMG_142.jpg', 'IMG_1421.jpg', 'IMG_1469.jpg', 'IMG_1488.jpg', 'IMG_1533.jpg', 'IMG_1577.jpg', 'IMG_1579.jpg', 'IMG_160.jpg', 'IMG_1626.jpg', 'IMG_1648.jpg', 'IMG_165.jpg', 'IMG_1705.jpg', 'IMG_1718.jpg', 'IMG_1739.jpg', 'IMG_1757.jpg', 'IMG_1804.jpg', 'IMG_1823.jpg', 'IMG_189.jpg', 'IMG_1893.jpg', 'IMG_1938.jpg', 'IMG_196.jpg', 'IMG_201.jpg', 'IMG_253.jpg', 'IMG_255.jpg', 'IMG_265.jpg', 'IMG_271.jpg', 'IMG_28.jpg', 'IMG_310.jpg', 'IMG_318.jpg', 'IMG_33.jpg', 'IMG_349.jpg', 'IMG_369.jpg', 'IMG_430.jpg', 'IMG_433.jpg', 'IMG_436.jpg', 'IMG_440.jpg', 'IMG_489.jpg', 'IMG_496.jpg', 'IMG_509.jpg', 'IMG_533.jpg', 'IMG_548.jpg', 'IMG_600.jpg'], 'computer-monitor': ['IMG_1060.jpg', 'IMG_1070.jpg', 'IMG_1076.jpg', 'IMG_1082.jpg', 'IMG_1098.jpg', 'IMG_1142.jpg', 'IMG_1152.jpg', 'IMG_1153.jpg', 'IMG_1166.jpg', 'IMG_1173.jpg', 'IMG_1184.jpg', 'IMG_120.jpg', 'IMG_1208.jpg', 'IMG_1290.jpg', 'IMG_1293.jpg', 'IMG_1297.jpg', 'IMG_1325.jpg', 'IMG_1328.jpg', 'IMG_1341.jpg', 'IMG_1391.jpg', 'IMG_1407.jpg', 'IMG_1411.jpg', 'IMG_1424.jpg', 'IMG_1427.jpg', 'IMG_1465.jpg', 'IMG_1521.jpg', 'IMG_1539.jpg', 'IMG_1549.jpg', 'IMG_1555.jpg', 'IMG_156.jpg', 'IMG_157.jpg', 'IMG_1683.jpg', 'IMG_1738.jpg', 'IMG_1750.jpg', 'IMG_1752.jpg', 'IMG_177.jpg', 'IMG_1806.jpg', 'IMG_182.jpg', 'IMG_1853.jpg', 'IMG_1857.jpg', 'IMG_1867.jpg', 'IMG_1870.jpg', 'IMG_1880.jpg', 'IMG_1905.jpg', 'IMG_1916.jpg', 'IMG_1963.jpg', 'IMG_1965.jpg', 'IMG_2036.jpg', 'IMG_2050.jpg', 'IMG_215.jpg', 'IMG_238.jpg', 'IMG_239.jpg', 'IMG_257.jpg', 'IMG_275.jpg', 'IMG_288.jpg', 'IMG_291.jpg', 'IMG_300.jpg', 'IMG_327.jpg', 'IMG_341.jpg', 'IMG_344.jpg', 'IMG_350.jpg', 'IMG_368.jpg', 'IMG_370.jpg', 'IMG_375.jpg', 'IMG_402.jpg', 'IMG_403.jpg', 'IMG_406.jpg', 'IMG_43.jpg', 'IMG_450.jpg', 'IMG_452.jpg', 'IMG_459.jpg', 'IMG_488.jpg', 'IMG_492.jpg', 'IMG_516.jpg', 'IMG_523.jpg', 'IMG_532.jpg', 'IMG_545.jpg', 'IMG_547.jpg', 'IMG_568.jpg', 'IMG_574.jpg'], 'bear': ['IMG_498.jpg', 'IMG_1008.jpg', 'IMG_1016.jpg', 'IMG_1030.jpg', 'IMG_1033.jpg', 'IMG_1040.jpg', 'IMG_108.jpg', 'IMG_1104.jpg', 'IMG_1128.jpg', 'IMG_116.jpg', 'IMG_1167.jpg', 'IMG_1204.jpg', 'IMG_1243.jpg', 'IMG_130.jpg', 'IMG_1315.jpg', 'IMG_1369.jpg', 'IMG_1389.jpg', 'IMG_1390.jpg', 'IMG_1396.jpg', 'IMG_1583.jpg', 'IMG_1595.jpg', 'IMG_1601.jpg', 'IMG_1611.jpg', 'IMG_1631.jpg', 'IMG_1652.jpg', 'IMG_1653.jpg', 'IMG_1658.jpg', 'IMG_166.jpg', 'IMG_1668.jpg', 'IMG_1692.jpg', 'IMG_171.jpg', 'IMG_1712.jpg', 'IMG_1722.jpg', 'IMG_1727.jpg', 'IMG_1748.jpg', 'IMG_1785.jpg', 'IMG_179.jpg', 'IMG_1860.jpg', 'IMG_1873.jpg', 'IMG_1886.jpg', 'IMG_1906.jpg', 'IMG_1910.jpg', 'IMG_1953.jpg', 'IMG_1957.jpg', 'IMG_2012.jpg', 'IMG_207.jpg', 'IMG_224.jpg', 'IMG_282.jpg', 'IMG_309.jpg', 'IMG_360.jpg', 'IMG_362.jpg', 'IMG_380.jpg', 'IMG_389.jpg', 'IMG_416.jpg', 'IMG_418.jpg', 'IMG_427.jpg', 'IMG_447.jpg', 'IMG_46.jpg', 'IMG_52.jpg', 'IMG_549.jpg', 'IMG_644.jpg', 'IMG_657.jpg'], 'grand-piano': ['IMG_1017.jpg', 'IMG_1122.jpg', 'IMG_1132.jpg', 'IMG_1154.jpg', 'IMG_1156.jpg', 'IMG_1224.jpg', 'IMG_1266.jpg', 'IMG_1282.jpg', 'IMG_1323.jpg', 'IMG_133.jpg', 'IMG_1379.jpg', 'IMG_140.jpg', 'IMG_1455.jpg', 'IMG_1467.jpg', 'IMG_1485.jpg', 'IMG_1493.jpg', 'IMG_1503.jpg', 'IMG_1504.jpg', 'IMG_1527.jpg', 'IMG_1594.jpg', 'IMG_1630.jpg', 'IMG_1655.jpg', 'IMG_1666.jpg', 'IMG_1691.jpg', 'IMG_1717.jpg', 'IMG_1719.jpg', 'IMG_1729.jpg', 'IMG_173.jpg', 'IMG_176.jpg', 'IMG_1763.jpg', 'IMG_1827.jpg', 'IMG_1832.jpg', 'IMG_1845.jpg', 'IMG_1875.jpg', 'IMG_1881.jpg', 'IMG_1925.jpg', 'IMG_1931.jpg', 'IMG_1945.jpg', 'IMG_1969.jpg', 'IMG_1988.jpg', 'IMG_202.jpg', 'IMG_2035.jpg', 'IMG_2037.jpg', 'IMG_250.jpg', 'IMG_27.jpg', 'IMG_294.jpg', 'IMG_340.jpg', 'IMG_425.jpg', 'IMG_426.jpg', 'IMG_438.jpg', 'IMG_474.jpg', 'IMG_504.jpg', 'IMG_528.jpg', 'IMG_552.jpg', 'IMG_559.jpg', 'IMG_584.jpg'], 'kangaroo': ['IMG_10.jpg', 'IMG_1079.jpg', 'IMG_115.jpg', 'IMG_1205.jpg', 'IMG_1271.jpg', 'IMG_1278.jpg', 'IMG_1311.jpg', 'IMG_1374.jpg', 'IMG_1394.jpg', 'IMG_1412.jpg', 'IMG_1430.jpg', 'IMG_1446.jpg', 'IMG_1524.jpg', 'IMG_1534.jpg', 'IMG_1562.jpg', 'IMG_1571.jpg', 'IMG_1582.jpg', 'IMG_1588.jpg', 'IMG_1597.jpg', 'IMG_1607.jpg', 'IMG_1636.jpg', 'IMG_1637.jpg', 'IMG_1681.jpg', 'IMG_1701.jpg', 'IMG_1743.jpg', 'IMG_1745.jpg', 'IMG_1762.jpg', 'IMG_1770.jpg', 'IMG_180.jpg', 'IMG_1815.jpg', 'IMG_1834.jpg', 'IMG_1887.jpg', 'IMG_1895.jpg', 'IMG_1944.jpg', 'IMG_2029.jpg', 'IMG_2032.jpg', 'IMG_2046.jpg', 'IMG_29.jpg', 'IMG_303.jpg', 'IMG_306.jpg', 'IMG_325.jpg', 'IMG_376.jpg', 'IMG_475.jpg', 'IMG_503.jpg', 'IMG_570.jpg', 'IMG_687.jpg'], 'laptop': ['IMG_1002.jpg', 'IMG_1004.jpg', 'IMG_1024.jpg', 'IMG_1093.jpg', 'IMG_110.jpg', 'IMG_1100.jpg', 'IMG_1107.jpg', 'IMG_1140.jpg', 'IMG_1161.jpg', 'IMG_1193.jpg', 'IMG_12.jpg', 'IMG_1216.jpg', 'IMG_1226.jpg', 'IMG_124.jpg', 'IMG_1249.jpg', 'IMG_1257.jpg', 'IMG_1272.jpg', 'IMG_1302.jpg', 'IMG_1305.jpg', 'IMG_1345.jpg', 'IMG_1350.jpg', 'IMG_1353.jpg', 'IMG_1360.jpg', 'IMG_1392.jpg', 'IMG_1400.jpg', 'IMG_1404.jpg', 'IMG_145.jpg', 'IMG_1450.jpg', 'IMG_1454.jpg', 'IMG_1470.jpg', 'IMG_1507.jpg', 'IMG_1522.jpg', 'IMG_1528.jpg', 'IMG_1548.jpg', 'IMG_1556.jpg', 'IMG_158.jpg', 'IMG_1584.jpg', 'IMG_16.jpg', 'IMG_1602.jpg', 'IMG_1608.jpg', 'IMG_1647.jpg', 'IMG_1649.jpg', 'IMG_1682.jpg', 'IMG_1696.jpg', 'IMG_1704.jpg', 'IMG_1751.jpg', 'IMG_1758.jpg', 'IMG_1807.jpg', 'IMG_1840.jpg', 'IMG_1859.jpg', 'IMG_1894.jpg', 'IMG_1973.jpg', 'IMG_1974.jpg', 'IMG_2015.jpg', 'IMG_2024.jpg', 'IMG_2028.jpg', 'IMG_2043.jpg', 'IMG_221.jpg', 'IMG_225.jpg', 'IMG_241.jpg', 'IMG_266.jpg', 'IMG_283.jpg', 'IMG_289.jpg', 'IMG_297.jpg', 'IMG_328.jpg', 'IMG_335.jpg', 'IMG_343.jpg', 'IMG_372.jpg', 'IMG_386.jpg', 'IMG_387.jpg', 'IMG_388.jpg', 'IMG_393.jpg', 'IMG_4.jpg', 'IMG_482.jpg', 'IMG_562.jpg', 'IMG_564.jpg', 'IMG_576.jpg', 'IMG_578.jpg', 'IMG_60.jpg', 'IMG_626.jpg']}, 'validation': {'owl': ['IMG_571.jpg', 'IMG_575.jpg', 'IMG_595.jpg', 'IMG_612.jpg', 'IMG_65.jpg', 'IMG_661.jpg', 'IMG_688.jpg', 'IMG_689.jpg', 'IMG_733.jpg', 'IMG_749.jpg', 'IMG_76.jpg', 'IMG_78.jpg', 'IMG_781.jpg', 'IMG_808.jpg', 'IMG_814.jpg', 'IMG_842.jpg', 'IMG_846.jpg', 'IMG_899.jpg', 'IMG_973.jpg'], 'galaxy': ['IMG_613.jpg', 'IMG_651.jpg', 'IMG_672.jpg', 'IMG_700.jpg', 'IMG_731.jpg', 'IMG_735.jpg', 'IMG_748.jpg', 'IMG_765.jpg', 'IMG_778.jpg', 'IMG_83.jpg', 'IMG_951.jpg'], 'lightning': ['IMG_483.jpg', 'IMG_54.jpg', 'IMG_544.jpg', 'IMG_557.jpg', 'IMG_573.jpg', 'IMG_71.jpg', 'IMG_75.jpg', 'IMG_753.jpg', 'IMG_762.jpg', 'IMG_772.jpg', 'IMG_777.jpg', 'IMG_784.jpg', 'IMG_855.jpg', 'IMG_86.jpg', 'IMG_860.jpg', 'IMG_947.jpg', 'IMG_962.jpg', 'IMG_963.jpg', 'IMG_964.jpg', 'IMG_992.jpg'], 'wine-bottle': ['IMG_1835.jpg', 'IMG_1838.jpg', 'IMG_188.jpg', 'IMG_1889.jpg', 'IMG_1917.jpg', 'IMG_2006.jpg', 'IMG_222.jpg', 'IMG_317.jpg', 'IMG_346.jpg', 'IMG_422.jpg', 'IMG_84.jpg', 'IMG_888.jpg', 'IMG_916.jpg', 'IMG_939.jpg', 'IMG_994.jpg'], 't-shirt': ['IMG_323.jpg', 'IMG_348.jpg', 'IMG_356.jpg', 'IMG_363.jpg', 'IMG_38.jpg', 'IMG_39.jpg', 'IMG_408.jpg', 'IMG_411.jpg', 'IMG_412.jpg', 'IMG_469.jpg', 'IMG_486.jpg', 'IMG_494.jpg', 'IMG_495.jpg', 'IMG_526.jpg', 'IMG_555.jpg', 'IMG_927.jpg', 'IMG_93.jpg', 'IMG_97.jpg', 'IMG_985.jpg', 'IMG_99.jpg'], 'waterfall': ['IMG_2033.jpg', 'IMG_1774.jpg', 'IMG_655.jpg', 'IMG_656.jpg', 'IMG_659.jpg', 'IMG_716.jpg', 'IMG_729.jpg', 'IMG_757.jpg', 'IMG_849.jpg', 'IMG_891.jpg', 'IMG_892.jpg', 'IMG_909.jpg', 'IMG_941.jpg', 'IMG_955.jpg'], 'sword': ['IMG_1.jpg', 'IMG_1027.jpg', 'IMG_1055.jpg', 'IMG_1089.jpg', 'IMG_55.jpg', 'IMG_590.jpg', 'IMG_623.jpg', 'IMG_631.jpg', 'IMG_662.jpg', 'IMG_945.jpg', 'IMG_953.jpg', 'IMG_961.jpg', 'IMG_981.jpg', 'IMG_991.jpg', 'IMG_993.jpg'], 'school-bus': ['IMG_725.jpg', 'IMG_754.jpg', 'IMG_770.jpg', 'IMG_799.jpg', 'IMG_841.jpg', 'IMG_850.jpg', 'IMG_858.jpg', 'IMG_868.jpg', 'IMG_88.jpg', 'IMG_898.jpg', 'IMG_900.jpg', 'IMG_920.jpg', 'IMG_928.jpg', 'IMG_954.jpg', 'IMG_990.jpg'], 'calculator': ['IMG_62.jpg', 'IMG_620.jpg', 'IMG_634.jpg', 'IMG_652.jpg', 'IMG_654.jpg', 'IMG_812.jpg', 'IMG_821.jpg', 'IMG_847.jpg', 'IMG_863.jpg', 'IMG_865.jpg', 'IMG_871.jpg', 'IMG_872.jpg', 'IMG_882.jpg', 'IMG_926.jpg', 'IMG_949.jpg'], 'sheet-music': ['IMG_81.jpg', 'IMG_810.jpg', 'IMG_816.jpg', 'IMG_822.jpg', 'IMG_824.jpg', 'IMG_856.jpg', 'IMG_906.jpg', 'IMG_910.jpg', 'IMG_918.jpg', 'IMG_935.jpg', 'IMG_970.jpg', 'IMG_997.jpg'], 'airplanes': ['IMG_668.jpg', 'IMG_670.jpg', 'IMG_690.jpg', 'IMG_696.jpg', 'IMG_707.jpg', 'IMG_713.jpg', 'IMG_769.jpg', 'IMG_779.jpg', 'IMG_793.jpg', 'IMG_796.jpg', 'IMG_798.jpg', 'IMG_836.jpg', 'IMG_869.jpg', 'IMG_879.jpg', 'IMG_903.jpg', 'IMG_948.jpg', 'IMG_960.jpg', 'IMG_968.jpg', 'IMG_969.jpg', 'IMG_971.jpg'], 'lightbulb': ['IMG_520.jpg', 'IMG_534.jpg', 'IMG_633.jpg', 'IMG_771.jpg', 'IMG_831.jpg', 'IMG_834.jpg', 'IMG_857.jpg', 'IMG_937.jpg', 'IMG_946.jpg', 'IMG_958.jpg', 'IMG_978.jpg', 'IMG_979.jpg', 'IMG_995.jpg'], 'skyscraper': ['IMG_1517.jpg', 'IMG_1547.jpg', 'IMG_1564.jpg', 'IMG_1566.jpg', 'IMG_1567.jpg', 'IMG_1606.jpg', 'IMG_1610.jpg', 'IMG_1625.jpg', 'IMG_1632.jpg', 'IMG_1672.jpg', 'IMG_1688.jpg', 'IMG_1695.jpg', 'IMG_1721.jpg', 'IMG_1775.jpg'], 'mountain-bike': ['IMG_698.jpg', 'IMG_726.jpg', 'IMG_732.jpg', 'IMG_768.jpg', 'IMG_79.jpg', 'IMG_830.jpg', 'IMG_839.jpg', 'IMG_889.jpg', 'IMG_911.jpg', 'IMG_921.jpg', 'IMG_974.jpg'], 'fireworks': ['IMG_627.jpg', 'IMG_63.jpg', 'IMG_630.jpg', 'IMG_649.jpg', 'IMG_737.jpg', 'IMG_761.jpg', 'IMG_767.jpg', 'IMG_801.jpg', 'IMG_820.jpg', 'IMG_85.jpg', 'IMG_853.jpg', 'IMG_854.jpg', 'IMG_881.jpg', 'IMG_894.jpg', 'IMG_896.jpg'], 'computer-monitor': ['IMG_580.jpg', 'IMG_591.jpg', 'IMG_642.jpg', 'IMG_658.jpg', 'IMG_665.jpg', 'IMG_7.jpg', 'IMG_70.jpg', 'IMG_701.jpg', 'IMG_714.jpg', 'IMG_720.jpg', 'IMG_746.jpg', 'IMG_751.jpg', 'IMG_766.jpg', 'IMG_787.jpg', 'IMG_804.jpg', 'IMG_885.jpg', 'IMG_902.jpg', 'IMG_905.jpg', 'IMG_924.jpg', 'IMG_987.jpg'], 'bear': ['IMG_677.jpg', 'IMG_686.jpg', 'IMG_747.jpg', 'IMG_760.jpg', 'IMG_77.jpg', 'IMG_783.jpg', 'IMG_832.jpg', 'IMG_840.jpg', 'IMG_87.jpg', 'IMG_895.jpg', 'IMG_90.jpg', 'IMG_966.jpg', 'IMG_976.jpg', 'IMG_977.jpg', 'IMG_996.jpg'], 'grand-piano': ['IMG_64.jpg', 'IMG_680.jpg', 'IMG_685.jpg', 'IMG_694.jpg', 'IMG_776.jpg', 'IMG_788.jpg', 'IMG_80.jpg', 'IMG_838.jpg', 'IMG_870.jpg', 'IMG_901.jpg', 'IMG_930.jpg', 'IMG_936.jpg', 'IMG_940.jpg', 'IMG_988.jpg'], 'kangaroo': ['IMG_692.jpg', 'IMG_723.jpg', 'IMG_792.jpg', 'IMG_795.jpg', 'IMG_827.jpg', 'IMG_851.jpg', 'IMG_908.jpg', 'IMG_929.jpg', 'IMG_95.jpg', 'IMG_975.jpg', 'IMG_980.jpg'], 'laptop': ['IMG_628.jpg', 'IMG_639.jpg', 'IMG_648.jpg', 'IMG_663.jpg', 'IMG_676.jpg', 'IMG_734.jpg', 'IMG_736.jpg', 'IMG_740.jpg', 'IMG_742.jpg', 'IMG_780.jpg', 'IMG_786.jpg', 'IMG_790.jpg', 'IMG_874.jpg', 'IMG_91.jpg', 'IMG_925.jpg', 'IMG_934.jpg', 'IMG_957.jpg', 'IMG_972.jpg', 'IMG_983.jpg', 'IMG_984.jpg']}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yP85YhYol8ER",
        "outputId": "a71778e7-b069-459a-d5e3-387b9761406d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "round(len(images)*0.8)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uh68rmWspp0U",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join(base_dir, 'train') # train directiry \n",
        "val_dir = os.path.join(base_dir, 'val')    # validation directory"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWLzhT96gAE-",
        "colab_type": "text"
      },
      "source": [
        "In the cell below, ImageDataGenerator transform and rescale the images by 255 \n",
        "\n",
        "flow_from_directory method to apply the above transformation to the images in the training set. batch size, the path to the directory of the training images, the target size for the images, to shuffle the images, the class mode is set to sparse\n",
        "\n",
        "same applies to validation side but without augmnetation nor shuffling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bi1_vHyBVrW2",
        "outputId": "dfc70aa3-5a44-4f02-b5c9-abf1af233d75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "batch_size = 32\n",
        "IMG_SHAPE = 224\n",
        "\n",
        "image_gen_train = ImageDataGenerator(\n",
        "                   rescale=1./255,               \n",
        "                   vertical_flip = True,\n",
        "                   horizontal_flip = True,\n",
        "                   rotation_range=45,\n",
        "                   zoom_range=0.5,                                \n",
        "                   )\n",
        "\n",
        "train_data_gen = image_gen_train.flow_from_directory(\n",
        "                                                batch_size=32,\n",
        "                                                directory=train_dir,\n",
        "                                                classes = class_list,\n",
        "                                                shuffle=True,\n",
        "                                                target_size=(IMG_SHAPE,IMG_SHAPE),\n",
        "                                                class_mode='sparse',\n",
        "                                                seed = rand_seed\n",
        "                                                \n",
        "                                                )\n",
        "\n",
        "\n",
        "image_gen_val = ImageDataGenerator(rescale=1./255)\n",
        "val_data_gen = image_gen_val.flow_from_directory(\n",
        "                                                 batch_size=16,\n",
        "                                                 directory=val_dir,\n",
        "                                                 classes = class_list,\n",
        "                                                 shuffle=True,\n",
        "                                                 target_size=(IMG_SHAPE, IMG_SHAPE),\n",
        "                                                 class_mode='sparse',\n",
        "                                                 seed = rand_seed\n",
        "                                                 )"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1245 images belonging to 20 classes.\n",
            "Found 309 images belonging to 20 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZmY6dQVj69F",
        "colab_type": "text"
      },
      "source": [
        "convolutional neural network that consists of 6 convolution blocks. Each convolutional block contains a Conv2D layer followed by a max pool layer.\n",
        "\n",
        "After the 6 convolutional blocks a flatten layer is added and is followed by a fully connected layer with 512 units. The CNN outputs class probabilities based on 20 classes which is done by the softmax activation function. All other layers use a relu activation function. add Dropout layers 0.2 probability is added"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Evjf8jZk2zi-",
        "outputId": "55184e9a-d2cb-4322-ab8c-35c3b603a9e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=8, kernel_size=3,strides=1, padding='same', activation='relu', input_shape=(224, 224, 3)))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(filters=16, kernel_size=3,strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=3,strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=3,strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=3,strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=3,strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters=512, kernel_size=3,strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(2056, kernel_initializer=keras.initializers.glorot_uniform(seed=rand_seed) ,activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Dense(1024, kernel_initializer=keras.initializers.glorot_uniform(seed=rand_seed) ,activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Dense(1024, kernel_initializer=keras.initializers.glorot_uniform(seed=rand_seed) ,activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Dense(512, kernel_initializer=keras.initializers.glorot_uniform(seed=rand_seed) ,activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "\n",
        "model.add(Dense(20, kernel_initializer=keras.initializers.glorot_uniform(seed=rand_seed), activation='softmax'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 224, 224, 8)       224       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 112, 112, 8)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 112, 112, 8)       32        \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 112, 112, 16)      1168      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 56, 56, 16)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 56, 56, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 56, 56, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 28, 28, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 14, 14, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 7, 7, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 3, 3, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 3, 3, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 1, 1, 512)         2048      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2056)              1054728   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2056)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1024)              2106368   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 20)                10260     \n",
            "=================================================================\n",
            "Total params: 6,323,532\n",
            "Trainable params: 6,321,500\n",
            "Non-trainable params: 2,032\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pab_29pnrUs3",
        "colab_type": "text"
      },
      "source": [
        "class wieghts are used to deal with the imbalance in the data set. later on these realtive weights are inputted to the model.fit_generator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN68gQoVw27t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_weights = {\n",
        "\t\t0\t:\t1.052631579\t,\n",
        "\t\t1\t:\t1.538461538\t,\n",
        "\t\t2\t:\t1\t,\n",
        "\t\t3\t:\t1.315789474\t,\n",
        "\t\t4\t:\t1\t,\n",
        "\t\t5\t:\t1.428571429\t,\n",
        "\t\t6\t:\t1.298701299\t,\n",
        "\t\t7\t:\t1.369863014\t,\n",
        "\t\t8\t:\t1.333333333\t,\n",
        "\t\t9\t:\t1.694915254\t,\n",
        "\t\t10\t:\t1\t,\n",
        "\t\t11\t:\t1.492537313\t,\n",
        "\t\t12\t:\t1.428571429\t,\n",
        "\t\t13\t:\t1.754385965\t,\n",
        "\t\t14\t:\t1.333333333\t,\n",
        "\t\t15\t:\t1\t,\n",
        "\t\t16\t:\t1.298701299\t,\n",
        "\t\t17\t:\t1.428571429\t,\n",
        "\t\t18\t:\t1.754385965\t,\n",
        "\t\t19\t:\t1\t\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtOxNl88lZsq",
        "colab_type": "text"
      },
      "source": [
        "The cell below compiles the model. ADAM and SGD optimizers are added for experimenting, the sparse cross entropy function as a loss functn look and training and validation accuracy on each epoch as we train our network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SlpIsU3enlJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "041bb963-9420-496a-db55-e3db57c2aa57"
      },
      "source": [
        "epochs = 100\n",
        "learning_rate = 0.001\n",
        "decay_rate = learning_rate / epochs\n",
        "\n",
        "opt1 = SGD(lr=learning_rate,\n",
        "            momentum = 0.08, \n",
        "            decay = decay_rate\n",
        "           )\n",
        "\n",
        "opt2 = Adam(lr=learning_rate, \n",
        "            beta_1=0.9, beta_2=0.999, epsilon=None, \n",
        "            decay=decay_rate, amsgrad=False)\n",
        "\n",
        "model.compile(optimizer=opt2,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6i0rvVJl6vf",
        "colab_type": "text"
      },
      "source": [
        "The cell below trains model using the fit_generator function. checkpoint are included to capture the best validtion_loss weights and class wieghts take care of the imbalance in the data set  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tk5NT1PW3j_P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "123e10c5-61c0-4708-84fa-d235f3836795"
      },
      "source": [
        "checkpointer = ModelCheckpoint(filepath='/content/drive/My Drive/weights.best.basic_model.hdf5', \n",
        "                               monitor='val_loss',\n",
        "                               verbose=1, \n",
        "                               save_best_only=True\n",
        "                               )\n",
        "\n",
        "history = model.fit_generator(\n",
        "                              train_data_gen,\n",
        "                              steps_per_epoch=int(np.ceil(train_data_gen.n / float(batch_size))),\n",
        "                              epochs=100,\n",
        "                              validation_data=val_data_gen,\n",
        "                              validation_steps=int(np.ceil(val_data_gen.n / float(batch_size))),\n",
        "                              callbacks = [checkpointer],\n",
        "                              class_weight = class_weights,\n",
        "                              verbose=1\n",
        "                              )"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/100\n",
            "39/39 [==============================] - 19s 491ms/step - loss: 4.1058 - acc: 0.0810 - val_loss: 2.8258 - val_acc: 0.1625\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.82585, saving model to /content/drive/My Drive/weights.best.basic_model.hdf5\n",
            "Epoch 2/100\n",
            "39/39 [==============================] - 15s 390ms/step - loss: 3.6561 - acc: 0.1302 - val_loss: 2.7729 - val_acc: 0.1812\n",
            "\n",
            "Epoch 00002: val_loss improved from 2.82585 to 2.77288, saving model to /content/drive/My Drive/weights.best.basic_model.hdf5\n",
            "Epoch 3/100\n",
            "39/39 [==============================] - 17s 433ms/step - loss: 3.5187 - acc: 0.1648 - val_loss: 2.4725 - val_acc: 0.2250\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.77288 to 2.47248, saving model to /content/drive/My Drive/weights.best.basic_model.hdf5\n",
            "Epoch 4/100\n",
            "39/39 [==============================] - 17s 434ms/step - loss: 3.3580 - acc: 0.1995 - val_loss: 2.5823 - val_acc: 0.1745\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 2.47248\n",
            "Epoch 5/100\n",
            "39/39 [==============================] - 17s 434ms/step - loss: 3.2873 - acc: 0.2026 - val_loss: 2.4963 - val_acc: 0.2625\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 2.47248\n",
            "Epoch 6/100\n",
            "39/39 [==============================] - 17s 431ms/step - loss: 3.1910 - acc: 0.2392 - val_loss: 2.3141 - val_acc: 0.2886\n",
            "\n",
            "Epoch 00006: val_loss improved from 2.47248 to 2.31405, saving model to /content/drive/My Drive/weights.best.basic_model.hdf5\n",
            "Epoch 7/100\n",
            "39/39 [==============================] - 17s 436ms/step - loss: 3.1990 - acc: 0.2220 - val_loss: 2.4214 - val_acc: 0.2250\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 2.31405\n",
            "Epoch 8/100\n",
            "39/39 [==============================] - 17s 426ms/step - loss: 3.1179 - acc: 0.2581 - val_loss: 2.6477 - val_acc: 0.2819\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 2.31405\n",
            "Epoch 9/100\n",
            "39/39 [==============================] - 17s 435ms/step - loss: 3.0691 - acc: 0.2474 - val_loss: 2.2726 - val_acc: 0.2750\n",
            "\n",
            "Epoch 00009: val_loss improved from 2.31405 to 2.27264, saving model to /content/drive/My Drive/weights.best.basic_model.hdf5\n",
            "Epoch 10/100\n",
            "39/39 [==============================] - 17s 431ms/step - loss: 3.0526 - acc: 0.2659 - val_loss: 2.3391 - val_acc: 0.2617\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 2.27264\n",
            "Epoch 11/100\n",
            "39/39 [==============================] - 17s 431ms/step - loss: 3.0098 - acc: 0.2552 - val_loss: 2.2990 - val_acc: 0.2500\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 2.27264\n",
            "Epoch 12/100\n",
            "39/39 [==============================] - 17s 424ms/step - loss: 2.9413 - acc: 0.2826 - val_loss: 2.0461 - val_acc: 0.3624\n",
            "\n",
            "Epoch 00012: val_loss improved from 2.27264 to 2.04606, saving model to /content/drive/My Drive/weights.best.basic_model.hdf5\n",
            "Epoch 13/100\n",
            "39/39 [==============================] - 17s 439ms/step - loss: 3.0261 - acc: 0.2874 - val_loss: 2.1991 - val_acc: 0.3125\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 2.04606\n",
            "Epoch 14/100\n",
            "39/39 [==============================] - 17s 430ms/step - loss: 2.9191 - acc: 0.2885 - val_loss: 2.3803 - val_acc: 0.2886\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 2.04606\n",
            "Epoch 15/100\n",
            "39/39 [==============================] - 17s 431ms/step - loss: 2.8699 - acc: 0.2989 - val_loss: 2.1279 - val_acc: 0.3125\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 2.04606\n",
            "Epoch 16/100\n",
            "39/39 [==============================] - 17s 428ms/step - loss: 2.7765 - acc: 0.3274 - val_loss: 2.1634 - val_acc: 0.3154\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 2.04606\n",
            "Epoch 17/100\n",
            "39/39 [==============================] - 17s 434ms/step - loss: 2.8483 - acc: 0.3174 - val_loss: 2.0056 - val_acc: 0.4250\n",
            "\n",
            "Epoch 00017: val_loss improved from 2.04606 to 2.00562, saving model to /content/drive/My Drive/weights.best.basic_model.hdf5\n",
            "Epoch 18/100\n",
            "39/39 [==============================] - 17s 442ms/step - loss: 2.7579 - acc: 0.3166 - val_loss: 2.3290 - val_acc: 0.3087\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 2.00562\n",
            "Epoch 19/100\n",
            "39/39 [==============================] - 17s 434ms/step - loss: 2.6755 - acc: 0.3388 - val_loss: 2.2771 - val_acc: 0.3125\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 2.00562\n",
            "Epoch 20/100\n",
            "39/39 [==============================] - 17s 427ms/step - loss: 2.6840 - acc: 0.3396 - val_loss: 2.1005 - val_acc: 0.3624\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 2.00562\n",
            "Epoch 21/100\n",
            "39/39 [==============================] - 17s 430ms/step - loss: 2.6863 - acc: 0.3467 - val_loss: 2.6429 - val_acc: 0.2812\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 2.00562\n",
            "Epoch 22/100\n",
            "39/39 [==============================] - 17s 431ms/step - loss: 2.7421 - acc: 0.3520 - val_loss: 1.7729 - val_acc: 0.4698\n",
            "\n",
            "Epoch 00022: val_loss improved from 2.00562 to 1.77292, saving model to /content/drive/My Drive/weights.best.basic_model.hdf5\n",
            "Epoch 23/100\n",
            "39/39 [==============================] - 17s 442ms/step - loss: 2.7400 - acc: 0.3391 - val_loss: 2.1121 - val_acc: 0.3688\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.77292\n",
            "Epoch 24/100\n",
            "39/39 [==============================] - 17s 426ms/step - loss: 2.6389 - acc: 0.3469 - val_loss: 2.0491 - val_acc: 0.3490\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.77292\n",
            "Epoch 25/100\n",
            "39/39 [==============================] - 17s 426ms/step - loss: 2.6749 - acc: 0.3607 - val_loss: 1.8898 - val_acc: 0.4000\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.77292\n",
            "Epoch 26/100\n",
            "39/39 [==============================] - 17s 430ms/step - loss: 2.6363 - acc: 0.3605 - val_loss: 1.8044 - val_acc: 0.4564\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.77292\n",
            "Epoch 27/100\n",
            "39/39 [==============================] - 17s 437ms/step - loss: 2.5506 - acc: 0.3822 - val_loss: 1.8295 - val_acc: 0.4875\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.77292\n",
            "Epoch 28/100\n",
            "39/39 [==============================] - 17s 428ms/step - loss: 2.4605 - acc: 0.3921 - val_loss: 1.9280 - val_acc: 0.4295\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.77292\n",
            "Epoch 29/100\n",
            "39/39 [==============================] - 17s 434ms/step - loss: 2.4949 - acc: 0.3734 - val_loss: 1.8365 - val_acc: 0.4750\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.77292\n",
            "Epoch 30/100\n",
            "39/39 [==============================] - 17s 428ms/step - loss: 2.5057 - acc: 0.3952 - val_loss: 1.8782 - val_acc: 0.3960\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.77292\n",
            "Epoch 31/100\n",
            "39/39 [==============================] - 17s 431ms/step - loss: 2.4668 - acc: 0.4204 - val_loss: 1.9113 - val_acc: 0.4000\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 1.77292\n",
            "Epoch 32/100\n",
            "39/39 [==============================] - 17s 430ms/step - loss: 2.5315 - acc: 0.3822 - val_loss: 2.2159 - val_acc: 0.3691\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 1.77292\n",
            "Epoch 33/100\n",
            "39/39 [==============================] - 17s 436ms/step - loss: 2.4467 - acc: 0.3921 - val_loss: 1.7915 - val_acc: 0.4000\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 1.77292\n",
            "Epoch 34/100\n",
            "39/39 [==============================] - 17s 426ms/step - loss: 2.4196 - acc: 0.4289 - val_loss: 1.8838 - val_acc: 0.4631\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 1.77292\n",
            "Epoch 35/100\n",
            "39/39 [==============================] - 17s 433ms/step - loss: 2.3279 - acc: 0.4210 - val_loss: 1.7286 - val_acc: 0.4688\n",
            "\n",
            "Epoch 00035: val_loss improved from 1.77292 to 1.72857, saving model to /content/drive/My Drive/weights.best.basic_model.hdf5\n",
            "Epoch 36/100\n",
            "39/39 [==============================] - 17s 435ms/step - loss: 2.3462 - acc: 0.4385 - val_loss: 1.7474 - val_acc: 0.5168\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.72857\n",
            "Epoch 37/100\n",
            "39/39 [==============================] - 17s 441ms/step - loss: 2.3224 - acc: 0.4440 - val_loss: 1.7643 - val_acc: 0.4188\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.72857\n",
            "Epoch 38/100\n",
            "39/39 [==============================] - 17s 427ms/step - loss: 2.3173 - acc: 0.4415 - val_loss: 1.6024 - val_acc: 0.5034\n",
            "\n",
            "Epoch 00038: val_loss improved from 1.72857 to 1.60236, saving model to /content/drive/My Drive/weights.best.basic_model.hdf5\n",
            "Epoch 39/100\n",
            "39/39 [==============================] - 17s 436ms/step - loss: 2.3693 - acc: 0.4185 - val_loss: 1.8853 - val_acc: 0.4625\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 1.60236\n",
            "Epoch 40/100\n",
            "39/39 [==============================] - 17s 429ms/step - loss: 2.2774 - acc: 0.4427 - val_loss: 1.9895 - val_acc: 0.5638\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 1.60236\n",
            "Epoch 41/100\n",
            "39/39 [==============================] - 17s 435ms/step - loss: 2.3256 - acc: 0.4385 - val_loss: 1.9689 - val_acc: 0.4625\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 1.60236\n",
            "Epoch 42/100\n",
            "39/39 [==============================] - 17s 429ms/step - loss: 2.2679 - acc: 0.4630 - val_loss: 1.6132 - val_acc: 0.4698\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 1.60236\n",
            "Epoch 43/100\n",
            "39/39 [==============================] - 17s 429ms/step - loss: 2.2134 - acc: 0.4572 - val_loss: 1.6508 - val_acc: 0.4500\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 1.60236\n",
            "Epoch 44/100\n",
            "39/39 [==============================] - 17s 428ms/step - loss: 2.1733 - acc: 0.4655 - val_loss: 1.6919 - val_acc: 0.4564\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 1.60236\n",
            "Epoch 45/100\n",
            "39/39 [==============================] - 17s 429ms/step - loss: 2.1918 - acc: 0.4646 - val_loss: 1.5196 - val_acc: 0.5437\n",
            "\n",
            "Epoch 00045: val_loss improved from 1.60236 to 1.51962, saving model to /content/drive/My Drive/weights.best.basic_model.hdf5\n",
            "Epoch 46/100\n",
            "39/39 [==============================] - 17s 434ms/step - loss: 2.1869 - acc: 0.4821 - val_loss: 2.0701 - val_acc: 0.4027\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 1.51962\n",
            "Epoch 47/100\n",
            "39/39 [==============================] - 17s 430ms/step - loss: 2.2827 - acc: 0.4710 - val_loss: 1.6919 - val_acc: 0.4688\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 1.51962\n",
            "Epoch 48/100\n",
            "39/39 [==============================] - 17s 430ms/step - loss: 2.2268 - acc: 0.4643 - val_loss: 1.5814 - val_acc: 0.5235\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 1.51962\n",
            "Epoch 49/100\n",
            "39/39 [==============================] - 17s 435ms/step - loss: 2.1939 - acc: 0.4951 - val_loss: 1.5815 - val_acc: 0.5563\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 1.51962\n",
            "Epoch 50/100\n",
            "39/39 [==============================] - 16s 420ms/step - loss: 2.1815 - acc: 0.4810 - val_loss: 1.6829 - val_acc: 0.4698\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 1.51962\n",
            "Epoch 51/100\n",
            "39/39 [==============================] - 17s 438ms/step - loss: 2.1367 - acc: 0.4918 - val_loss: 1.7504 - val_acc: 0.4938\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 1.51962\n",
            "Epoch 52/100\n",
            "39/39 [==============================] - 17s 429ms/step - loss: 2.0326 - acc: 0.5117 - val_loss: 1.5948 - val_acc: 0.5638\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 1.51962\n",
            "Epoch 53/100\n",
            "39/39 [==============================] - 17s 424ms/step - loss: 2.2383 - acc: 0.4803 - val_loss: 1.6476 - val_acc: 0.5125\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 1.51962\n",
            "Epoch 54/100\n",
            "39/39 [==============================] - 17s 429ms/step - loss: 2.1333 - acc: 0.4988 - val_loss: 1.4725 - val_acc: 0.5235\n",
            "\n",
            "Epoch 00054: val_loss improved from 1.51962 to 1.47248, saving model to /content/drive/My Drive/weights.best.basic_model.hdf5\n",
            "Epoch 55/100\n",
            "39/39 [==============================] - 17s 446ms/step - loss: 2.0459 - acc: 0.5062 - val_loss: 1.8595 - val_acc: 0.4562\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 1.47248\n",
            "Epoch 56/100\n",
            "39/39 [==============================] - 17s 431ms/step - loss: 2.1391 - acc: 0.4855 - val_loss: 1.8690 - val_acc: 0.4832\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 1.47248\n",
            "Epoch 57/100\n",
            "39/39 [==============================] - 17s 431ms/step - loss: 2.0846 - acc: 0.4997 - val_loss: 1.6231 - val_acc: 0.5687\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 1.47248\n",
            "Epoch 58/100\n",
            "39/39 [==============================] - 17s 430ms/step - loss: 2.0283 - acc: 0.5121 - val_loss: 1.3994 - val_acc: 0.5705\n",
            "\n",
            "Epoch 00058: val_loss improved from 1.47248 to 1.39939, saving model to /content/drive/My Drive/weights.best.basic_model.hdf5\n",
            "Epoch 59/100\n",
            "39/39 [==============================] - 17s 437ms/step - loss: 1.8154 - acc: 0.5378 - val_loss: 1.3934 - val_acc: 0.6000\n",
            "\n",
            "Epoch 00059: val_loss improved from 1.39939 to 1.39336, saving model to /content/drive/My Drive/weights.best.basic_model.hdf5\n",
            "Epoch 60/100\n",
            "39/39 [==============================] - 17s 431ms/step - loss: 2.0859 - acc: 0.5028 - val_loss: 1.6401 - val_acc: 0.4966\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 1.39336\n",
            "Epoch 61/100\n",
            "39/39 [==============================] - 17s 436ms/step - loss: 1.9242 - acc: 0.5283 - val_loss: 1.4027 - val_acc: 0.5375\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 1.39336\n",
            "Epoch 62/100\n",
            "39/39 [==============================] - 17s 427ms/step - loss: 1.9951 - acc: 0.5254 - val_loss: 1.4573 - val_acc: 0.5369\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 1.39336\n",
            "Epoch 63/100\n",
            "39/39 [==============================] - 17s 427ms/step - loss: 1.9890 - acc: 0.5337 - val_loss: 1.6365 - val_acc: 0.5500\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 1.39336\n",
            "Epoch 64/100\n",
            "39/39 [==============================] - 17s 430ms/step - loss: 1.8890 - acc: 0.5391 - val_loss: 1.2299 - val_acc: 0.6711\n",
            "\n",
            "Epoch 00064: val_loss improved from 1.39336 to 1.22990, saving model to /content/drive/My Drive/weights.best.basic_model.hdf5\n",
            "Epoch 65/100\n",
            "39/39 [==============================] - 17s 445ms/step - loss: 1.9663 - acc: 0.5395 - val_loss: 1.4419 - val_acc: 0.5563\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 1.22990\n",
            "Epoch 66/100\n",
            "39/39 [==============================] - 17s 426ms/step - loss: 1.8873 - acc: 0.5399 - val_loss: 1.4466 - val_acc: 0.5570\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 1.22990\n",
            "Epoch 67/100\n",
            "39/39 [==============================] - 17s 431ms/step - loss: 1.9202 - acc: 0.5342 - val_loss: 1.8063 - val_acc: 0.4562\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 1.22990\n",
            "Epoch 68/100\n",
            "39/39 [==============================] - 17s 430ms/step - loss: 1.8438 - acc: 0.5711 - val_loss: 1.5188 - val_acc: 0.5101\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 1.22990\n",
            "Epoch 69/100\n",
            "39/39 [==============================] - 17s 431ms/step - loss: 1.8862 - acc: 0.5629 - val_loss: 1.5913 - val_acc: 0.5437\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 1.22990\n",
            "Epoch 70/100\n",
            "39/39 [==============================] - 17s 432ms/step - loss: 1.8262 - acc: 0.5559 - val_loss: 1.4750 - val_acc: 0.6443\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 1.22990\n",
            "Epoch 71/100\n",
            "39/39 [==============================] - 17s 430ms/step - loss: 1.7657 - acc: 0.5742 - val_loss: 1.2388 - val_acc: 0.6312\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 1.22990\n",
            "Epoch 72/100\n",
            "39/39 [==============================] - 17s 428ms/step - loss: 1.8577 - acc: 0.5558 - val_loss: 1.4829 - val_acc: 0.6174\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 1.22990\n",
            "Epoch 73/100\n",
            "39/39 [==============================] - 17s 438ms/step - loss: 1.8451 - acc: 0.5710 - val_loss: 1.5185 - val_acc: 0.5375\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 1.22990\n",
            "Epoch 74/100\n",
            "39/39 [==============================] - 17s 428ms/step - loss: 1.8710 - acc: 0.5631 - val_loss: 1.6256 - val_acc: 0.5772\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 1.22990\n",
            "Epoch 75/100\n",
            "39/39 [==============================] - 17s 433ms/step - loss: 1.7372 - acc: 0.5834 - val_loss: 1.4221 - val_acc: 0.5687\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 1.22990\n",
            "Epoch 76/100\n",
            "39/39 [==============================] - 17s 433ms/step - loss: 1.7013 - acc: 0.6016 - val_loss: 1.3367 - val_acc: 0.6107\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 1.22990\n",
            "Epoch 77/100\n",
            "39/39 [==============================] - 17s 436ms/step - loss: 1.7728 - acc: 0.5830 - val_loss: 1.5245 - val_acc: 0.5813\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 1.22990\n",
            "Epoch 78/100\n",
            "39/39 [==============================] - 17s 434ms/step - loss: 1.7341 - acc: 0.5917 - val_loss: 1.5245 - val_acc: 0.6376\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 1.22990\n",
            "Epoch 79/100\n",
            "39/39 [==============================] - 17s 445ms/step - loss: 1.7086 - acc: 0.5971 - val_loss: 1.4989 - val_acc: 0.5312\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 1.22990\n",
            "Epoch 80/100\n",
            "39/39 [==============================] - 17s 428ms/step - loss: 1.7786 - acc: 0.5847 - val_loss: 1.4344 - val_acc: 0.5973\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 1.22990\n",
            "Epoch 81/100\n",
            "39/39 [==============================] - 17s 433ms/step - loss: 1.8047 - acc: 0.5727 - val_loss: 1.3470 - val_acc: 0.5938\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 1.22990\n",
            "Epoch 82/100\n",
            "39/39 [==============================] - 17s 428ms/step - loss: 1.7057 - acc: 0.5892 - val_loss: 1.5144 - val_acc: 0.5973\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 1.22990\n",
            "Epoch 83/100\n",
            "39/39 [==============================] - 17s 434ms/step - loss: 1.7472 - acc: 0.6008 - val_loss: 1.6073 - val_acc: 0.5188\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 1.22990\n",
            "Epoch 84/100\n",
            "39/39 [==============================] - 17s 431ms/step - loss: 1.6374 - acc: 0.6201 - val_loss: 1.4280 - val_acc: 0.5973\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 1.22990\n",
            "Epoch 85/100\n",
            "39/39 [==============================] - 17s 432ms/step - loss: 1.6732 - acc: 0.6013 - val_loss: 1.3030 - val_acc: 0.6312\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 1.22990\n",
            "Epoch 86/100\n",
            "39/39 [==============================] - 17s 425ms/step - loss: 1.6895 - acc: 0.6188 - val_loss: 1.3656 - val_acc: 0.6040\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 1.22990\n",
            "Epoch 87/100\n",
            "39/39 [==============================] - 17s 436ms/step - loss: 1.6935 - acc: 0.6003 - val_loss: 1.2863 - val_acc: 0.6312\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 1.22990\n",
            "Epoch 88/100\n",
            "39/39 [==============================] - 17s 428ms/step - loss: 1.6306 - acc: 0.6198 - val_loss: 1.6267 - val_acc: 0.5235\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 1.22990\n",
            "Epoch 89/100\n",
            "39/39 [==============================] - 17s 432ms/step - loss: 1.5504 - acc: 0.6289 - val_loss: 1.2711 - val_acc: 0.6438\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 1.22990\n",
            "Epoch 90/100\n",
            "39/39 [==============================] - 17s 429ms/step - loss: 1.6584 - acc: 0.6038 - val_loss: 1.3843 - val_acc: 0.6309\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 1.22990\n",
            "Epoch 91/100\n",
            "39/39 [==============================] - 17s 438ms/step - loss: 1.5653 - acc: 0.6411 - val_loss: 1.4458 - val_acc: 0.6562\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 1.22990\n",
            "Epoch 92/100\n",
            "39/39 [==============================] - 17s 433ms/step - loss: 1.5779 - acc: 0.6150 - val_loss: 1.5255 - val_acc: 0.6040\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 1.22990\n",
            "Epoch 93/100\n",
            "39/39 [==============================] - 17s 432ms/step - loss: 1.6257 - acc: 0.6133 - val_loss: 1.5627 - val_acc: 0.4938\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 1.22990\n",
            "Epoch 94/100\n",
            "39/39 [==============================] - 17s 431ms/step - loss: 1.5703 - acc: 0.6329 - val_loss: 1.4935 - val_acc: 0.6242\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 1.22990\n",
            "Epoch 95/100\n",
            "39/39 [==============================] - 17s 434ms/step - loss: 1.5955 - acc: 0.6376 - val_loss: 1.3716 - val_acc: 0.6312\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 1.22990\n",
            "Epoch 96/100\n",
            "39/39 [==============================] - 17s 430ms/step - loss: 1.5371 - acc: 0.6376 - val_loss: 1.2930 - val_acc: 0.5638\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 1.22990\n",
            "Epoch 97/100\n",
            "39/39 [==============================] - 17s 432ms/step - loss: 1.5008 - acc: 0.6359 - val_loss: 1.3748 - val_acc: 0.6312\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 1.22990\n",
            "Epoch 98/100\n",
            "39/39 [==============================] - 17s 430ms/step - loss: 1.5299 - acc: 0.6236 - val_loss: 1.4128 - val_acc: 0.6242\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 1.22990\n",
            "Epoch 99/100\n",
            "39/39 [==============================] - 17s 433ms/step - loss: 1.5562 - acc: 0.6458 - val_loss: 1.5617 - val_acc: 0.6188\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 1.22990\n",
            "Epoch 100/100\n",
            "39/39 [==============================] - 17s 427ms/step - loss: 1.6346 - acc: 0.6295 - val_loss: 1.6377 - val_acc: 0.5235\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 1.22990\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0NKzMk0mjJl",
        "colab_type": "text"
      },
      "source": [
        "visulizing the accuracies and losses of both training and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7W87CJUx2We",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "a5fb45a1-5df5-452a-fd85-e8f64b1585d5"
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-ab192aeb141e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6KqYKwPm6dc",
        "colab_type": "text"
      },
      "source": [
        "The remaining cells do proccesing to convert images to 4D, to predicat on the test data and to generate CSV submission for Kaggle. at the end the predicted image is plotted along with the respective model prediction  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xji9v3zD97po",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def path_to_tensor(img_path):\n",
        "    # loads RGB image as PIL.Image.Image type\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
        "    x = image.img_to_array(img)\n",
        "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
        "    return np.expand_dims(x, axis=0)\n",
        "\n",
        "def paths_to_tensor(img_paths):\n",
        "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
        "    return np.vstack(list_of_tensors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE5rtZcA4jJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('/content/drive/My Drive/checkpoints/weights.best.basic_model67.11.hdf5') # load the mode \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0CfKNs54hUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_img(img_path):\n",
        "    img=path_to_tensor(img_path).astype('float32')/255\n",
        "    # obtain predicted vector\n",
        "    predicted_vector = model.predict(img)\n",
        "    # return the index of the max value in the probability vector predicted by the model\n",
        "    return [np.argmax(predicted_vector)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdyzIxJP_Cm-",
        "colab_type": "code",
        "outputId": "8bc025e5-32cc-4e00-fddb-04bdee7b6271",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from keras.preprocessing import image\n",
        "(predict_img('/content/drive/My Drive/classification/classification/Classification_Dataset/test/IMG_1035.jpg'))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLHa6ROT4ila",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conversion2kaggle (prediction):\n",
        "    return {\n",
        "        '[12]'\t:\t12,\n",
        "        '[5]'\t  :\t5,\n",
        "        '[10]'\t:\t10,\n",
        "        '[19]'\t:\t19,\n",
        "        '[17]' \t:\t17,\n",
        "        '[18]'  :\t18,\n",
        "        '[16]'  :\t16,\n",
        "        '[13]'  :\t13,\n",
        "        '[2]'\t  :\t2,\n",
        "        '[14]'\t:\t14,\n",
        "        '[0]'\t  :\t0,\n",
        "        '[9]'\t  :\t9,\n",
        "        '[15]' \t:\t15,\n",
        "        '[11]'\t:\t11,\n",
        "        '[4]'\t  :\t4,\n",
        "        '[3]'\t  :\t3,\n",
        "        '[1]' \t:\t1,\n",
        "        '[6]'\t  :\t6,\n",
        "        '[7]'   :\t7,\n",
        "        '[8]'  \t:\t8,\n",
        "    }[prediction]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sONEepVm5CIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = load_files(\"/content/drive/My Drive/classification/classification/Classification_Dataset/test\") #this line takes too much time on colab to execute 5 min "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2laO2YhxkiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_csv(results, results_dir='./'):\n",
        "\n",
        "    csv_fname = 'results_'\n",
        "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
        "\n",
        "    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n",
        "\n",
        "        f.write('Id,Category\\n')\n",
        "\n",
        "        for key, value in results.items():\n",
        "            f.write(key + ',' + str(value) + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LULXO7VWxlSG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "outputId": "d8b2be96-6600-4960-8a7d-53d0433c8ea2"
      },
      "source": [
        "image_list = []\n",
        "results = {}\n",
        "\n",
        "for filename in glob.glob('/content/drive/My Drive/classification/classification/Classification_Dataset/test/*.jpg'): \n",
        "    image_list.append(filename)\n",
        "\n",
        "\n",
        "for image_name in image_list:\n",
        "    results[os.path.basename(image_name)]=conversion2kaggle((str(predict_img(image_name))))\n",
        "\n",
        "print(results)\n",
        "create_csv(results)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'IMG_0.jpg': 19, 'IMG_1001.jpg': 5, 'IMG_299.jpg': 14, 'IMG_1042.jpg': 18, 'IMG_104.jpg': 12, 'IMG_1011.jpg': 15, 'IMG_1031.jpg': 11, 'IMG_1035.jpg': 5, 'IMG_1023.jpg': 3, 'IMG_1037.jpg': 7, 'IMG_1007.jpg': 14, 'IMG_1046.jpg': 19, 'IMG_1073.jpg': 7, 'IMG_1071.jpg': 5, 'IMG_1050.jpg': 5, 'IMG_1059.jpg': 16, 'IMG_106.jpg': 9, 'IMG_105.jpg': 7, 'IMG_1058.jpg': 10, 'IMG_1052.jpg': 11, 'IMG_1072.jpg': 14, 'IMG_1074.jpg': 7, 'IMG_1080.jpg': 8, 'IMG_1090.jpg': 12, 'IMG_1094.jpg': 7, 'IMG_113.jpg': 17, 'IMG_1133.jpg': 5, 'IMG_1097.jpg': 16, 'IMG_1101.jpg': 15, 'IMG_1117.jpg': 10, 'IMG_1099.jpg': 11, 'IMG_1119.jpg': 4, 'IMG_1137.jpg': 14, 'IMG_1084.jpg': 5, 'IMG_1127.jpg': 7, 'IMG_1143.jpg': 11, 'IMG_1147.jpg': 13, 'IMG_1183.jpg': 2, 'IMG_1163.jpg': 14, 'IMG_1179.jpg': 11, 'IMG_1174.jpg': 19, 'IMG_1148.jpg': 16, 'IMG_1158.jpg': 5, 'IMG_1172.jpg': 15, 'IMG_1155.jpg': 8, 'IMG_117.jpg': 12, 'IMG_1187.jpg': 2, 'IMG_119.jpg': 9, 'IMG_1211.jpg': 15, 'IMG_1199.jpg': 6, 'IMG_1194.jpg': 3, 'IMG_1197.jpg': 2, 'IMG_1212.jpg': 4, 'IMG_1202.jpg': 8, 'IMG_1209.jpg': 4, 'IMG_121.jpg': 4, 'IMG_1196.jpg': 1, 'IMG_1206.jpg': 4, 'IMG_1213.jpg': 10, 'IMG_1214.jpg': 19, 'IMG_1240.jpg': 9, 'IMG_1235.jpg': 14, 'IMG_123.jpg': 16, 'IMG_1228.jpg': 17, 'IMG_1229.jpg': 2, 'IMG_1238.jpg': 5, 'IMG_1232.jpg': 12, 'IMG_1217.jpg': 15, 'IMG_1241.jpg': 5, 'IMG_1242.jpg': 0, 'IMG_1219.jpg': 2, 'IMG_1248.jpg': 5, 'IMG_1251.jpg': 17, 'IMG_129.jpg': 16, 'IMG_1264.jpg': 17, 'IMG_1283.jpg': 2, 'IMG_1280.jpg': 7, 'IMG_1285.jpg': 8, 'IMG_1289.jpg': 8, 'IMG_1270.jpg': 8, 'IMG_1276.jpg': 8, 'IMG_1268.jpg': 12, 'IMG_1298.jpg': 16, 'IMG_13.jpg': 5, 'IMG_1307.jpg': 12, 'IMG_1342.jpg': 12, 'IMG_134.jpg': 12, 'IMG_1306.jpg': 6, 'IMG_1334.jpg': 8, 'IMG_1330.jpg': 15, 'IMG_1308.jpg': 4, 'IMG_1339.jpg': 2, 'IMG_1318.jpg': 16, 'IMG_1322.jpg': 8, 'IMG_1344.jpg': 5, 'IMG_1346.jpg': 14, 'IMG_1349.jpg': 14, 'IMG_1382.jpg': 4, 'IMG_1359.jpg': 3, 'IMG_1354.jpg': 19, 'IMG_137.jpg': 8, 'IMG_135.jpg': 10, 'IMG_1363.jpg': 9, 'IMG_136.jpg': 4, 'IMG_1384.jpg': 10, 'IMG_1397.jpg': 17, 'IMG_1377.jpg': 15, 'IMG_1370.jpg': 18, 'IMG_1406.jpg': 11, 'IMG_1415.jpg': 14, 'IMG_1442.jpg': 16, 'IMG_1422.jpg': 17, 'IMG_1429.jpg': 14, 'IMG_1437.jpg': 3, 'IMG_1435.jpg': 0, 'IMG_1419.jpg': 18, 'IMG_144.jpg': 11, 'IMG_1420.jpg': 14, 'IMG_1436.jpg': 19, 'IMG_1444.jpg': 2, 'IMG_1449.jpg': 19, 'IMG_1452.jpg': 12, 'IMG_1480.jpg': 0, 'IMG_1466.jpg': 10, 'IMG_1462.jpg': 4, 'IMG_1459.jpg': 4, 'IMG_1468.jpg': 16, 'IMG_1474.jpg': 2, 'IMG_1483.jpg': 12, 'IMG_1484.jpg': 0, 'IMG_1475.jpg': 14, 'IMG_1481.jpg': 4, 'IMG_1494.jpg': 19, 'IMG_1495.jpg': 7, 'IMG_1516.jpg': 10, 'IMG_1512.jpg': 4, 'IMG_1501.jpg': 1, 'IMG_1506.jpg': 3, 'IMG_1511.jpg': 11, 'IMG_1502.jpg': 2, 'IMG_1520.jpg': 8, 'IMG_1500.jpg': 15, 'IMG_151.jpg': 7, 'IMG_1509.jpg': 4, 'IMG_1529.jpg': 2, 'IMG_153.jpg': 3, 'IMG_1551.jpg': 2, 'IMG_1544.jpg': 17, 'IMG_1543.jpg': 17, 'IMG_1532.jpg': 17, 'IMG_1541.jpg': 4, 'IMG_1538.jpg': 8, 'IMG_1536.jpg': 2, 'IMG_1552.jpg': 17, 'IMG_1557.jpg': 18, 'IMG_1550.jpg': 4, 'IMG_1546.jpg': 0, 'IMG_1560.jpg': 13, 'IMG_1575.jpg': 13, 'IMG_1618.jpg': 11, 'IMG_1593.jpg': 12, 'IMG_1589.jpg': 1, 'IMG_1600.jpg': 12, 'IMG_1591.jpg': 12, 'IMG_1620.jpg': 13, 'IMG_1603.jpg': 1, 'IMG_159.jpg': 16, 'IMG_1609.jpg': 18, 'IMG_1604.jpg': 16, 'IMG_1622.jpg': 12, 'IMG_1623.jpg': 5, 'IMG_1628 (1).jpg': 10, 'IMG_1659 (1).jpg': 6, 'IMG_1645 (1).jpg': 19, 'IMG_1657 (1).jpg': 6, 'IMG_163 (1).jpg': 2, 'IMG_1650 (1).jpg': 12, 'IMG_1646 (1).jpg': 2, 'IMG_1661.jpg': 11, 'IMG_1664.jpg': 15, 'IMG_1633 (1).jpg': 1, 'IMG_167.jpg': 6, 'IMG_1674.jpg': 14, 'IMG_1684.jpg': 13, 'IMG_169.jpg': 17, 'IMG_1699.jpg': 13, 'IMG_1703.jpg': 15, 'IMG_1706.jpg': 15, 'IMG_1709.jpg': 11, 'IMG_1713.jpg': 13, 'IMG_1723.jpg': 10, 'IMG_1728.jpg': 6, 'IMG_1734.jpg': 15, 'IMG_174.jpg': 1, 'IMG_1741.jpg': 11, 'IMG_1744.jpg': 4, 'IMG_1747.jpg': 1, 'IMG_175.jpg': 11, 'IMG_1756.jpg': 16, 'IMG_1761.jpg': 16, 'IMG_1764.jpg': 14, 'IMG_1768.jpg': 13, 'IMG_1771.jpg': 18, 'IMG_1780.jpg': 14, 'IMG_1798.jpg': 0, 'IMG_1799.jpg': 18, 'IMG_1802.jpg': 5, 'IMG_1803.jpg': 16, 'IMG_1808.jpg': 16, 'IMG_1811.jpg': 11, 'IMG_1813.jpg': 8, 'IMG_1814.jpg': 5, 'IMG_1819.jpg': 8, 'IMG_1820.jpg': 9, 'IMG_1826.jpg': 10, 'IMG_183.jpg': 15, 'IMG_1831.jpg': 17, 'IMG_1836.jpg': 17, 'IMG_1837.jpg': 3, 'IMG_1842.jpg': 1, 'IMG_1849.jpg': 11, 'IMG_1851.jpg': 16, 'IMG_1852.jpg': 8, 'IMG_1854.jpg': 14, 'IMG_1858.jpg': 12, 'IMG_1865.jpg': 3, 'IMG_1871.jpg': 9, 'IMG_1872.jpg': 4, 'IMG_1878.jpg': 18, 'IMG_1882.jpg': 15, 'IMG_1883.jpg': 2, 'IMG_1885.jpg': 7, 'IMG_1890.jpg': 17, 'IMG_1892.jpg': 6, 'IMG_1899.jpg': 13, 'IMG_19.jpg': 17, 'IMG_1901.jpg': 17, 'IMG_1902.jpg': 6, 'IMG_1907.jpg': 1, 'IMG_1908.jpg': 17, 'IMG_1909.jpg': 5, 'IMG_1912.jpg': 2, 'IMG_1915.jpg': 3, 'IMG_1918.jpg': 13, 'IMG_1919.jpg': 0, 'IMG_1923.jpg': 7, 'IMG_1929.jpg': 11, 'IMG_1935.jpg': 4, 'IMG_1936.jpg': 17, 'IMG_1941.jpg': 3, 'IMG_1949.jpg': 2, 'IMG_195.jpg': 7, 'IMG_1961.jpg': 13, 'IMG_1962.jpg': 11, 'IMG_1966.jpg': 4, 'IMG_1971.jpg': 19, 'IMG_1975.jpg': 7, 'IMG_1977.jpg': 18, 'IMG_1978.jpg': 9, 'IMG_1979.jpg': 18, 'IMG_1982.jpg': 8, 'IMG_1989.jpg': 1, 'IMG_1991.jpg': 18, 'IMG_2000.jpg': 4, 'IMG_2005.jpg': 11, 'IMG_2007.jpg': 9, 'IMG_2010.jpg': 12, 'IMG_2017.jpg': 10, 'IMG_2018.jpg': 14, 'IMG_2020.jpg': 18, 'IMG_2021.jpg': 17, 'IMG_2023.jpg': 17, 'IMG_2025.jpg': 1, 'IMG_2031.jpg': 2, 'IMG_2041.jpg': 6, 'IMG_2042.jpg': 7, 'IMG_2047.jpg': 2, 'IMG_2052.jpg': 14, 'IMG_2053.jpg': 3, 'IMG_206.jpg': 5, 'IMG_214.jpg': 17, 'IMG_217.jpg': 8, 'IMG_220.jpg': 3, 'IMG_223.jpg': 5, 'IMG_227.jpg': 13, 'IMG_228.jpg': 18, 'IMG_233.jpg': 8, 'IMG_234.jpg': 5, 'IMG_237.jpg': 17, 'IMG_24.jpg': 11, 'IMG_240.jpg': 14, 'IMG_245.jpg': 16, 'IMG_249.jpg': 1, 'IMG_251.jpg': 17, 'IMG_252.jpg': 6, 'IMG_261.jpg': 14, 'IMG_262.jpg': 3, 'IMG_263.jpg': 7, 'IMG_264.jpg': 7, 'IMG_267.jpg': 16, 'IMG_269.jpg': 10, 'IMG_270.jpg': 4, 'IMG_272.jpg': 11, 'IMG_273.jpg': 7, 'IMG_278.jpg': 9, 'IMG_279.jpg': 1, 'IMG_280.jpg': 4, 'IMG_285.jpg': 16, 'IMG_293.jpg': 11, 'IMG_295.jpg': 17, 'IMG_296.jpg': 11, 'IMG_298.jpg': 0, 'IMG_30.jpg': 17, 'IMG_307.jpg': 7, 'IMG_308.jpg': 14, 'IMG_31.jpg': 8, 'IMG_312.jpg': 9, 'IMG_32.jpg': 10, 'IMG_321.jpg': 19, 'IMG_322.jpg': 11, 'IMG_329.jpg': 14, 'IMG_338.jpg': 8, 'IMG_34.jpg': 8, 'IMG_35.jpg': 10, 'IMG_355.jpg': 5, 'IMG_367.jpg': 16, 'IMG_37.jpg': 14, 'IMG_371.jpg': 12, 'IMG_377.jpg': 5, 'IMG_379.jpg': 7, 'IMG_383.jpg': 1, 'IMG_384.jpg': 14, 'IMG_385.jpg': 19, 'IMG_397.jpg': 7, 'IMG_400.jpg': 9, 'IMG_404.jpg': 14, 'IMG_405.jpg': 7, 'IMG_410.jpg': 10, 'IMG_414.jpg': 18, 'IMG_420.jpg': 14, 'IMG_421.jpg': 2, 'IMG_423.jpg': 17, 'IMG_451.jpg': 12, 'IMG_455.jpg': 16, 'IMG_461.jpg': 8, 'IMG_467.jpg': 17, 'IMG_473.jpg': 19, 'IMG_478.jpg': 3, 'IMG_48.jpg': 19, 'IMG_480.jpg': 16, 'IMG_485.jpg': 7, 'IMG_487.jpg': 19, 'IMG_497.jpg': 15, 'IMG_499.jpg': 17, 'IMG_501.jpg': 5, 'IMG_505.jpg': 16, 'IMG_507.jpg': 1, 'IMG_508.jpg': 1, 'IMG_51.jpg': 19, 'IMG_512.jpg': 10, 'IMG_513.jpg': 17, 'IMG_515.jpg': 1, 'IMG_517.jpg': 15, 'IMG_524.jpg': 2, 'IMG_53.jpg': 1, 'IMG_535.jpg': 19, 'IMG_539.jpg': 4, 'IMG_542.jpg': 15, 'IMG_543.jpg': 12, 'IMG_546.jpg': 18, 'IMG_550.jpg': 2, 'IMG_551.jpg': 10, 'IMG_558.jpg': 19, 'IMG_561.jpg': 10, 'IMG_563.jpg': 19, 'IMG_567.jpg': 17, 'IMG_57.jpg': 2, 'IMG_572.jpg': 2, 'IMG_58.jpg': 2, 'IMG_581.jpg': 8, 'IMG_582.jpg': 14, 'IMG_583.jpg': 15, 'IMG_588.jpg': 11, 'IMG_59.jpg': 15, 'IMG_592.jpg': 9, 'IMG_597.jpg': 18, 'IMG_598.jpg': 18, 'IMG_6.jpg': 4, 'IMG_601.jpg': 0, 'IMG_602.jpg': 8, 'IMG_603.jpg': 2, 'IMG_606.jpg': 14, 'IMG_607.jpg': 8, 'IMG_608.jpg': 4, 'IMG_61.jpg': 19, 'IMG_616.jpg': 11, 'IMG_621.jpg': 12, 'IMG_635.jpg': 12, 'IMG_638.jpg': 3, 'IMG_641.jpg': 7, 'IMG_645.jpg': 12, 'IMG_647.jpg': 14, 'IMG_66.jpg': 8, 'IMG_660.jpg': 8, 'IMG_664.jpg': 0, 'IMG_667.jpg': 19, 'IMG_67.jpg': 11, 'IMG_671.jpg': 12, 'IMG_674.jpg': 9, 'IMG_679.jpg': 18, 'IMG_68.jpg': 1, 'IMG_681.jpg': 14, 'IMG_682.jpg': 9, 'IMG_69.jpg': 16, 'IMG_691.jpg': 9, 'IMG_695.jpg': 15, 'IMG_702.jpg': 1, 'IMG_703.jpg': 10, 'IMG_705.jpg': 3, 'IMG_706.jpg': 9, 'IMG_708.jpg': 19, 'IMG_709.jpg': 17, 'IMG_710.jpg': 4, 'IMG_711.jpg': 12, 'IMG_712.jpg': 16, 'IMG_717.jpg': 18, 'IMG_72.jpg': 14, 'IMG_722.jpg': 16, 'IMG_727.jpg': 8, 'IMG_730.jpg': 10, 'IMG_739.jpg': 5, 'IMG_74.jpg': 11, 'IMG_744.jpg': 9, 'IMG_752.jpg': 14, 'IMG_755.jpg': 9, 'IMG_756.jpg': 5, 'IMG_764.jpg': 5, 'IMG_775.jpg': 9, 'IMG_785.jpg': 1, 'IMG_789.jpg': 11, 'IMG_791.jpg': 12, 'IMG_794.jpg': 10, 'IMG_797.jpg': 8, 'IMG_802.jpg': 15, 'IMG_803.jpg': 10, 'IMG_805.jpg': 10, 'IMG_813.jpg': 2, 'IMG_815.jpg': 13, 'IMG_817.jpg': 16, 'IMG_823.jpg': 6, 'IMG_826.jpg': 7, 'IMG_828.jpg': 14, 'IMG_835.jpg': 13, 'IMG_837.jpg': 9, 'IMG_844.jpg': 17, 'IMG_845.jpg': 14, 'IMG_848.jpg': 16, 'IMG_852.jpg': 11, 'IMG_862.jpg': 18, 'IMG_864.jpg': 9, 'IMG_866.jpg': 16, 'IMG_867.jpg': 10, 'IMG_873.jpg': 13, 'IMG_876.jpg': 9, 'IMG_877.jpg': 5, 'IMG_878.jpg': 12, 'IMG_880.jpg': 16, 'IMG_884.jpg': 16, 'IMG_887.jpg': 5, 'IMG_89.jpg': 5, 'IMG_893.jpg': 3, 'IMG_897.jpg': 15, 'IMG_904.jpg': 14, 'IMG_907.jpg': 15, 'IMG_912.jpg': 11, 'IMG_913.jpg': 1, 'IMG_914.jpg': 9, 'IMG_917.jpg': 4, 'IMG_919.jpg': 9, 'IMG_92.jpg': 13, 'IMG_922.jpg': 0, 'IMG_923.jpg': 1, 'IMG_932.jpg': 10, 'IMG_938.jpg': 8, 'IMG_94.jpg': 17, 'IMG_942.jpg': 2, 'IMG_943.jpg': 3, 'IMG_944.jpg': 15, 'IMG_950.jpg': 11, 'IMG_952.jpg': 14, 'IMG_956.jpg': 4, 'IMG_959.jpg': 18, 'IMG_96.jpg': 10, 'IMG_965.jpg': 17, 'IMG_967.jpg': 19, 'IMG_98.jpg': 11, 'IMG_982.jpg': 15, 'IMG_986.jpg': 15, 'IMG_999.jpg': 1, 'IMG_1659.jpg': 6, 'IMG_1650.jpg': 12, 'IMG_1646.jpg': 2, 'IMG_1657.jpg': 6, 'IMG_1645.jpg': 19, 'IMG_1633.jpg': 1, 'IMG_1628.jpg': 10, 'IMG_163.jpg': 2, 'IMG_1643.jpg': 18}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OEo9eVjxqi2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "2defa079-5b7f-49de-a89a-6430cb5c77de"
      },
      "source": [
        "def show_img(img_path): \n",
        "  img = cv2.imread(img_path)\n",
        "  cv_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  plt.imshow(cv_rgb)\n",
        "  plt.show()\n",
        "  print(\"     Predicted as {}\\n\\n\\n\".format(class_list[conversion2kaggle((str(predict_img(img_path))))])\n",
        "  ) "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-30-50876ef7c98e>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5OcRxrsAiLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for path in image_list:\n",
        "  show_img(path)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}